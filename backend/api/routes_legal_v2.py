"""
Legal RAG API Routes v2
ë²•ë¥  ë¦¬ìŠ¤í¬ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸ (v2 - ê°€ì´ë“œ ìŠ¤í™ ì¤€ìˆ˜)
"""

from fastapi import APIRouter, UploadFile, File, Form, HTTPException, status, Query, Header
from typing import Optional, List
import tempfile
import os
import logging
import asyncio
from pathlib import Path
from datetime import datetime
import uuid
import re

from models.schemas import (
    ScriptsV2,
    LegalSearchResponseV2,
    LegalSearchResult,
    SituationRequestV2,
    SituationResponseV2,
    ContractAnalysisResponseV2,
    ContractIssueV2,
    ClauseV2,
    HighlightedTextV2,
    ContractComparisonRequestV2,
    ContractComparisonResponseV2,
    ClauseRewriteRequestV2,
    ClauseRewriteResponseV2,
    LegalChatRequestV2,
    LegalChatResponseV2,
    UsedChunksV2,
    UsedChunkV2,
    ConversationRequestV2,
)
from core.legal_rag_service import LegalRAGService
from core.document_processor_v2 import DocumentProcessor
from core.contract_storage import ContractStorageService
from core.tools import ClauseLabelingTool, HighlightTool, RewriteTool
from core.dependencies import (
    get_legal_service_dep,
    get_processor_dep,
    get_storage_service_dep,
)
from core.logging_config import get_logger

router = APIRouter(
    prefix="/api/v2/legal",
    tags=["legal-v2"],
)

# ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ (ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥)
def get_legal_service() -> LegalRAGService:
    """Legal RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë ˆê±°ì‹œ í˜¸í™˜)"""
    from core.dependencies import get_legal_service as _get_legal_service
    return _get_legal_service()

def get_processor() -> DocumentProcessor:
    """ë¬¸ì„œ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë ˆê±°ì‹œ í˜¸í™˜)"""
    from core.dependencies import get_processor as _get_processor
    return _get_processor()

def get_storage_service() -> ContractStorageService:
    """ê³„ì•½ì„œ ì €ì¥ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë ˆê±°ì‹œ í˜¸í™˜)"""
    from core.dependencies import get_storage_service as _get_storage_service
    return _get_storage_service()

# ì„ì‹œ íŒŒì¼ ë””ë ‰í† ë¦¬
TEMP_DIR = "./data/temp"
os.makedirs(TEMP_DIR, exist_ok=True)

# ê³„ì•½ì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥ì†Œ (fallbackìš©)
_contract_analyses = {}

logger = get_logger(__name__)


@router.get("/health")
async def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "message": "Linkus Public RAG API is running"
    }


@router.get("/search", response_model=LegalSearchResponseV2)
async def search_legal(
    q: str = Query(..., description="ê²€ìƒ‰ì–´"),
    limit: int = Query(5, ge=1, le=50, description="ê²°ê³¼ ê°œìˆ˜"),
    doc_type: Optional[str] = Query(None, description="ë¬¸ì„œ íƒ€ì… (law, standard_contract, manual, case)"),
):
    """
    ë²•ë ¹/í‘œì¤€ê³„ì•½/ë§¤ë‰´ì–¼/ì¼€ì´ìŠ¤ RAG ê²€ìƒ‰
    """
    try:
        service = get_legal_service()
        
        # RAG ê²€ìƒ‰ ìˆ˜í–‰
        chunks = await service._search_legal_chunks(query=q, top_k=limit)
        
        # ê²°ê³¼ ë³€í™˜ (LegalGroundingChunk ê°ì²´ë¥¼ dictë¡œ ë³€í™˜)
        results = []
        for chunk in chunks:
            result = LegalSearchResult(
                legal_document_id=chunk.source_id,
                section_title=None,  # LegalGroundingChunkì—ëŠ” ì—†ìŒ
                text=chunk.snippet,
                score=chunk.score,
                source=None,  # LegalGroundingChunkì—ëŠ” ì—†ìŒ
                doc_type=chunk.source_type,
                title=chunk.title,
            )
            results.append(result)
        
        return LegalSearchResponseV2(
            results=results,
            count=len(results),
            query=q,
        )
    except Exception as e:
        logger.error(f"ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë²•ë ¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.post("/analyze-contract", response_model=ContractAnalysisResponseV2)
async def analyze_contract(
    file: UploadFile = File(..., description="ê³„ì•½ì„œ íŒŒì¼ (PDF/HWPX ë“±)"),
    title: Optional[str] = Form(None, description="ë¬¸ì„œ ì´ë¦„"),
    doc_type: Optional[str] = Form(None, description="ë¬¸ì„œ íƒ€ì… (employment, freelance ë“±)"),
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ê³„ì•½ì„œ PDF/HWPX ì—…ë¡œë“œ â†’ ìœ„í—˜ ë¶„ì„
    """
    logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ========== v2 ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì‹œì‘ ==========")
    logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] íŒŒì¼ëª…: {file.filename}, title: {title}, doc_type: {doc_type}, user_id: {x_user_id}")
    
    if not file.filename:
        raise HTTPException(status_code=400, detail="íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    temp_path = None
    try:
        # íŒŒì¼ ì„ì‹œ ì €ì¥
        suffix = Path(file.filename).suffix if file.filename else ".tmp"
        temp_file = tempfile.NamedTemporaryFile(
            delete=False,
            suffix=suffix,
            dir=TEMP_DIR
        )
        temp_path = temp_file.name
        
        content = await file.read()
        temp_file.write(content)
        temp_file.close()
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        processor = get_processor()
        extracted_text, _ = processor.process_file(temp_path, file_type=None)
        
        # extracted_text ì¶”ì¶œ í™•ì¸ ë¡œê¹…
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: extracted_text ê¸¸ì´={len(extracted_text) if extracted_text else 0}, ë¯¸ë¦¬ë³´ê¸°={extracted_text[:100] if extracted_text else '(ì—†ìŒ)'}")
        
        if not extracted_text or extracted_text.strip() == "":
            logger.error(f"[ê³„ì•½ì„œ ë¶„ì„] í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: extracted_textê°€ ë¹„ì–´ìˆìŒ")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        # ê³„ì•½ì„œ ì¡°í•­ ë‹¨ìœ„ ì²­í‚¹ ë° ë²¡í„° ì €ì¥ (Dual RAGë¥¼ ìœ„í•´)
        doc_id = str(uuid.uuid4())
        doc_title = title or file.filename or "ê³„ì•½ì„œ"
        
        # contract_chunks ì €ì¥ì„ ë¨¼ì € ì™„ë£Œí•œ í›„ ë¶„ì„ ì‹œì‘ (Race condition í•´ê²°)
        async def prepare_contract_chunks():
            """ê³„ì•½ì„œ ì²­í‚¹ ë° ë²¡í„° ì €ì¥"""
            try:
                # 1. ì¡°í•­ ë‹¨ìœ„ ì²­í‚¹
                processor = get_processor()
                contract_chunks = processor.to_contract_chunks(
                    text=extracted_text,
                    base_meta={
                        "contract_id": doc_id,
                        "title": doc_title,
                        "filename": file.filename,
                    }
                )
                
                # 2. ì„ë² ë”© ìƒì„± (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ì—¬ ë¸”ë¡œí‚¹ ë°©ì§€)
                from core.generator_v2 import LLMGenerator
                generator = LLMGenerator()
                chunk_texts = [chunk.content for chunk in contract_chunks]
                embeddings = await asyncio.to_thread(generator.embed, chunk_texts)
                
                # 3. contract_chunks í…Œì´ë¸”ì— ì €ì¥
                from core.supabase_vector_store import SupabaseVectorStore
                vector_store = SupabaseVectorStore()
                
                chunk_payload = []
                for idx, chunk in enumerate(contract_chunks):
                    chunk_payload.append({
                        "article_number": chunk.metadata.get("article_number", 0),
                        "paragraph_index": chunk.metadata.get("paragraph_index"),
                        "content": chunk.content,
                        "chunk_index": chunk.index,
                        "chunk_type": chunk.metadata.get("chunk_type", "article"),
                        "embedding": embeddings[idx],
                        "metadata": chunk.metadata,
                    })
                
                vector_store.bulk_upsert_contract_chunks(
                    contract_id=doc_id,
                    chunks=chunk_payload
                )
                logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] contract_chunks ì €ì¥ ì™„ë£Œ: {len(chunk_payload)}ê°œ ì²­í¬")
                return True
            except Exception as chunk_error:
                logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] contract_chunks ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {str(chunk_error)}", exc_info=True)
                # ì²­í¬ ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ì€ ê³„ì† ì§„í–‰
                return False
        
        # contract_chunks ì €ì¥ì„ ë¨¼ì € ì™„ë£Œ
        chunks_saved = await prepare_contract_chunks()
        
        # ì €ì¥ ì™„ë£Œ í›„ ë¶„ì„ ì‹œì‘ (Dual RAGì—ì„œ contract_chunks ì‚¬ìš© ê°€ëŠ¥)
        async def analyze_contract_risk():
            """ë²•ë¥  ë¦¬ìŠ¤í¬ ë¶„ì„ (Dual RAG ì§€ì›)"""
            service = get_legal_service()
            # doc_idë¥¼ ì „ë‹¬í•˜ì—¬ contract_chunksë„ ê²€ìƒ‰
            # chunks_savedê°€ Trueë©´ contract_chunksê°€ ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ê²€ìƒ‰ ê°€ëŠ¥
            return await service.analyze_contract(
                extracted_text=extracted_text,
                description=None,
                doc_id=doc_id if chunks_saved else None,  # ì €ì¥ ì‹¤íŒ¨ ì‹œ None ì „ë‹¬
            )
        
        # ë¶„ì„ ì‹¤í–‰
        result = await analyze_contract_risk()
        
        # resultê°€ ì˜ˆì™¸ì¸ ê²½ìš° ì²˜ë¦¬ (ì´ë¯¸ await í–ˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ëŠ” ìë™ìœ¼ë¡œ ì „íŒŒë¨)
        if not result:
            logger.error(f"[ê³„ì•½ì„œ ë¶„ì„] ë¶„ì„ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ê³„ì•½ì„œ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            )
        
        # ì˜ì—­ë³„ ì ìˆ˜ ê³„ì‚° (ê¸°ì¡´ resultì—ì„œ ì¶”ì¶œ ë˜ëŠ” ê¸°ë³¸ê°’)
        sections = {
            "working_hours": 0,
            "wage": 0,
            "probation_termination": 0,
            "stock_option_ip": 0,
        }
        
        # issues ë³€í™˜ ë° originalText ê²€ì¦
        issues = []
        for idx, issue in enumerate(result.issues):
            # originalText ì¶”ì¶œ: LegalIssueì˜ original_text í•„ë“œ ìš°ì„  ì‚¬ìš©
            original_text = ""
            if hasattr(issue, 'original_text') and issue.original_text:
                original_text = issue.original_text
            elif issue.description:
                # í•˜ìœ„ í˜¸í™˜ì„±: original_textê°€ ì—†ìœ¼ë©´ description ì‚¬ìš©
                original_text = issue.description[:200]
            
            # originalText ê²€ì¦: ê³„ì•½ì„œ ì›ë¬¸ì— ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            original_text_validated = original_text
            if original_text and extracted_text:
                # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if extracted_text.find(original_text) < 0:
                    # ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
                    # originalTextì˜ ì²˜ìŒ 50ìë¡œ ê²€ìƒ‰
                    partial_match = extracted_text.find(original_text[:50])
                    if partial_match >= 0:
                        # ë¶€ë¶„ ë§¤ì¹­ëœ ê²½ìš°, í•´ë‹¹ ìœ„ì¹˜ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ í™•ì¥í•˜ì—¬ ì¶”ì¶œ
                        start_pos = partial_match
                        # ì•ìœ¼ë¡œ ë¬¸ì¥ ì‹œì‘ ì°¾ê¸°
                        while start_pos > 0 and extracted_text[start_pos] not in ['\n', 'ã€‚', '.']:
                            start_pos -= 1
                        start_pos = max(0, start_pos + 1)
                        # ë’¤ë¡œ ë¬¸ì¥ ë ì°¾ê¸°
                        end_pos = min(partial_match + len(original_text), len(extracted_text))
                        while end_pos < len(extracted_text) and extracted_text[end_pos] not in ['\n', 'ã€‚', '.']:
                            end_pos += 1
                        original_text_validated = extracted_text[start_pos:end_pos].strip()
                        logger.info(f"[originalText ê²€ì¦] issue-{idx+1}: ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ìˆ˜ì •ë¨ (ê¸¸ì´: {len(original_text)} -> {len(original_text_validated)})")
                    else:
                        logger.warning(f"[originalText ê²€ì¦] issue-{idx+1}: originalTextë¥¼ ê³„ì•½ì„œ ì›ë¬¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ. originalText ê¸¸ì´={len(original_text)}")
                        # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
            
            issue_v2 = ContractIssueV2(
                id=f"issue-{idx+1}",
                category=issue.name.lower().replace(" ", "_"),
                severity=issue.severity,
                summary=issue.description,
                originalText=original_text_validated,  # ê²€ì¦ëœ originalText ì‚¬ìš©
                legalBasis=issue.legal_basis,
                explanation=issue.rationale or issue.description,
                suggestedRevision=issue.suggested_text or "",
            )
            issues.append(issue_v2)
        
        # retrievedContexts ë³€í™˜
        retrieved_contexts = []
        for chunk in result.grounding:
            retrieved_contexts.append({
                "sourceType": chunk.source_type,
                "title": chunk.title,
                "snippet": chunk.snippet,
            })
        
        # ì¡°í•­ ìë™ ë¶„ë¥˜ ë° í•˜ì´ë¼ì´íŠ¸
        clauses = []
        highlighted_texts = []
        
        try:
            # 1. ì¡°í•­ ìë™ ë¶„ë¥˜
            labeling_tool = ClauseLabelingTool()
            labeling_result = await labeling_tool.execute(
                contract_text=extracted_text,
                issues=[issue.model_dump() for issue in issues]
            )
            
            clauses = [
                ClauseV2(
                    id=clause["id"],
                    title=clause["title"],
                    content=clause["content"],
                    articleNumber=clause.get("articleNumber"),
                    startIndex=clause.get("startIndex", 0),
                    endIndex=clause.get("endIndex", 0),
                    category=clause.get("category")
                )
                for clause in labeling_result.get("clauses", [])
            ]
            
            # issueì— clauseId ë§¤í•‘
            issue_clause_mapping = labeling_result.get("issue_clause_mapping", {})
            for issue_v2 in issues:
                matched_clause_ids = issue_clause_mapping.get(issue_v2.id, [])
                if matched_clause_ids:
                    issue_v2.clauseId = matched_clause_ids[0]  # ì²« ë²ˆì§¸ ë§¤ì¹­ëœ ì¡°í•­
            
            # 2. ìœ„í—˜ ì¡°í•­ í•˜ì´ë¼ì´íŠ¸
            highlight_tool = HighlightTool()
            highlight_result = await highlight_tool.execute(
                contract_text=extracted_text,
                issues=[issue.model_dump() for issue in issues]
            )
            
            highlighted_texts = [
                HighlightedTextV2(
                    text=ht["text"],
                    startIndex=ht["startIndex"],
                    endIndex=ht["endIndex"],
                    severity=ht["severity"],
                    issueId=ht["issueId"]
                )
                for ht in highlight_result.get("highlightedTexts", [])
            ]
            
            # issueì— startIndex, endIndex ì¶”ê°€
            for issue_v2 in issues:
                for ht in highlighted_texts:
                    if ht.issueId == issue_v2.id:
                        issue_v2.startIndex = ht.startIndex
                        issue_v2.endIndex = ht.endIndex
                        break
            
            logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ì¡°í•­ ë¶„ë¥˜ ì™„ë£Œ: {len(clauses)}ê°œ ì¡°í•­, {len(highlighted_texts)}ê°œ í•˜ì´ë¼ì´íŠ¸")
            
            # ê²€ì¦: clausesê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³ 
            if not clauses:
                logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] âš ï¸ ì¡°í•­ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³„ì•½ì„œì— 'ì œnì¡°' íŒ¨í„´ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ê²€ì¦: highlightedTextsê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³ 
            if not highlighted_texts and issues:
                logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] âš ï¸ í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. originalText ë§¤ì¹­ ì‹¤íŒ¨ ê°€ëŠ¥ì„±.")
                # originalTextê°€ ìˆëŠ” issues ê°œìˆ˜ í™•ì¸
                issues_with_original = sum(1 for issue in issues if issue.originalText and issue.originalText.strip())
                logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] originalTextê°€ ìˆëŠ” issues: {issues_with_original}/{len(issues)}ê°œ")
        except Exception as e:
            logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] ì¡°í•­ ë¶„ë¥˜/í•˜ì´ë¼ì´íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (clausesì™€ highlightedTextsëŠ” ë¹ˆ ë°°ì—´ë¡œ ìœ ì§€)
        
        # ê²°ê³¼ ì €ì¥ (DBì— ì €ì¥)
        # contractText ì„¤ì • ì „ í™•ì¸
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ContractAnalysisResponseV2 ìƒì„± ì „: extracted_text ê¸¸ì´={len(extracted_text) if extracted_text else 0}, extracted_text íƒ€ì…={type(extracted_text)}")
        
        # extracted_textê°€ Noneì´ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
        contract_text_value = extracted_text if extracted_text else ""
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] contractText ê°’ ì„¤ì •: ê¸¸ì´={len(contract_text_value)}, ë¹„ì–´ìˆìŒ={not contract_text_value or contract_text_value.strip() == ''}")
        
        analysis_result = ContractAnalysisResponseV2(
            docId=doc_id,
            title=doc_title,
            riskScore=result.risk_score,
            riskLevel=result.risk_level,
            sections=sections,
            issues=issues,
            summary=result.summary,
            retrievedContexts=retrieved_contexts,
            contractText=contract_text_value,  # ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸ í¬í•¨ (Noneì´ë©´ ë¹ˆ ë¬¸ìì—´)
            clauses=clauses,  # ì¡°í•­ ëª©ë¡
            highlightedTexts=highlighted_texts,  # í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸
            createdAt=datetime.utcnow().isoformat() + "Z",
        )
        
        # ìƒì„± í›„ í™•ì¸
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ContractAnalysisResponseV2 ìƒì„± í›„: contractText ê¸¸ì´={len(analysis_result.contractText) if analysis_result.contractText else 0}, contractText ì¡´ì¬={bool(analysis_result.contractText)}")
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ì‘ë‹µ ìƒì„± ì™„ë£Œ: docId={doc_id}, title={doc_title}, issues={len(issues)}ê°œ")
        
        # DBì— ì €ì¥ ì‹œë„
        try:
            storage_service = get_storage_service()
            # file_name í•„ë“œë¥¼ í™•ì‹¤í•˜ê²Œ ì±„ìš°ê¸° ìœ„í•´ ìš°ì„ ìˆœìœ„ ì ìš©
            # original_filenameì€ file.filename ë˜ëŠ” doc_title ì‚¬ìš©
            original_filename_for_db = file.filename if file.filename and file.filename.strip() else doc_title
            
            logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] DB ì €ì¥ ì‹œë„: doc_id={doc_id}, title={doc_title}, original_filename={original_filename_for_db}, file.filename={file.filename}")
            
            # DB ì €ì¥ ì „ ë°ì´í„° ìš”ì•½ ë¡œê¹…
            issues_for_db = [{
                "id": issue.id,
                "category": issue.category,
                "severity": issue.severity,
                "summary": issue.summary,
                "originalText": issue.originalText,
                "legalBasis": issue.legalBasis,
                "explanation": issue.explanation,
                "suggestedRevision": issue.suggestedRevision,
            } for issue in issues]
            
            logger.info(f"[DB ì €ì¥] ì €ì¥í•  ë°ì´í„° ìš”ì•½:")
            logger.info(f"  - doc_id: {doc_id}")
            logger.info(f"  - title: {doc_title}")
            logger.info(f"  - risk_score: {result.risk_score}, risk_level: {result.risk_level}")
            logger.info(f"  - summary ê¸¸ì´: {len(result.summary)}")
            logger.info(f"  - issues ê°œìˆ˜: {len(issues_for_db)}")
            logger.info(f"  - contract_text ê¸¸ì´: {len(extracted_text) if extracted_text else 0}")
            logger.info(f"  - retrieved_contexts ê°œìˆ˜: {len(retrieved_contexts)}")
            for idx, issue in enumerate(issues_for_db[:3]):  # ì²˜ìŒ 3ê°œë§Œ ë¡œê¹…
                logger.info(f"  - issue[{idx}]: id={issue['id']}, category={issue['category']}, severity={issue['severity']}, summary={issue['summary'][:50]}")
            
            # clausesì™€ highlightedTextsë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            clauses_for_db = [
                {
                    "id": clause.id,
                    "title": clause.title,
                    "content": clause.content,
                    "articleNumber": clause.articleNumber,
                    "startIndex": clause.startIndex,
                    "endIndex": clause.endIndex,
                    "category": clause.category,
                }
                for clause in clauses
            ] if clauses else []
            
            highlighted_texts_for_db = [
                {
                    "text": ht.text,
                    "startIndex": ht.startIndex,
                    "endIndex": ht.endIndex,
                    "severity": ht.severity,
                    "issueId": ht.issueId,
                }
                for ht in highlighted_texts
            ] if highlighted_texts else []
            
            await storage_service.save_contract_analysis(
                doc_id=doc_id,
                title=doc_title,
                original_filename=original_filename_for_db,  # file.filenameì´ Noneì´ë©´ doc_title ì‚¬ìš©
                doc_type=doc_type,
                risk_score=result.risk_score,
                risk_level=result.risk_level,
                sections=sections,
                summary=result.summary,
                retrieved_contexts=retrieved_contexts,
                issues=issues_for_db,
                user_id=x_user_id,
                contract_text=extracted_text,  # ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸ ì €ì¥
                clauses=clauses_for_db,  # ì¡°í•­ ëª©ë¡ ì €ì¥
                highlighted_texts=highlighted_texts_for_db,  # í•˜ì´ë¼ì´íŠ¸ëœ í…ìŠ¤íŠ¸ ì €ì¥
            )
            logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] DB ì €ì¥ ì™„ë£Œ: doc_id={doc_id}")
        except Exception as save_error:
            logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] DB ì €ì¥ ì‹¤íŒ¨, ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥: {str(save_error)}", exc_info=True)
            # Fallback: ë©”ëª¨ë¦¬ì— ì €ì¥
            _contract_analyses[doc_id] = analysis_result
            logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ë©”ëª¨ë¦¬ì— ì €ì¥ ì™„ë£Œ: doc_id={doc_id}, contractText ê¸¸ì´={len(analysis_result.contractText) if analysis_result.contractText else 0}")
        
        # ì‘ë‹µ ì§ë ¬í™” í™•ì¸
        response_dict = analysis_result.model_dump()
        contract_text_length = len(response_dict.get('contractText', '')) if response_dict.get('contractText') else 0
        
        # ìƒì„¸ ë¡œê¹…
        logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] ì‘ë‹µ ìƒì„± ì™„ë£Œ:")
        logger.info(f"  - docId: {response_dict.get('docId')}")
        logger.info(f"  - contractText ê¸¸ì´: {contract_text_length}")
        logger.info(f"  - contractText ì¡´ì¬: {bool(response_dict.get('contractText'))}")
        logger.info(f"  - contractText ë¯¸ë¦¬ë³´ê¸°: {response_dict.get('contractText', '')[:100] if response_dict.get('contractText') else '(ì—†ìŒ)'}")
        logger.info(f"  - ì‘ë‹µ í‚¤: {list(response_dict.keys())}")
        logger.info(f"  - issues ê°œìˆ˜: {len(response_dict.get('issues', []))}")
        logger.info(f"  - retrievedContexts ê°œìˆ˜: {len(response_dict.get('retrievedContexts', []))}")
        
        # contractTextê°€ ì—†ìœ¼ë©´ ê²½ê³ 
        if not response_dict.get('contractText') or contract_text_length == 0:
            logger.warning(f"[ê³„ì•½ì„œ ë¶„ì„] âš ï¸ contractTextê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤! extracted_text ê¸¸ì´: {len(extracted_text) if extracted_text else 0}")
        
        # v2 í˜•ì‹ ê²€ì¦: í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['docId', 'title', 'riskScore', 'riskLevel', 'sections', 'issues', 'summary', 'retrievedContexts', 'contractText', 'createdAt']
        missing_fields = [field for field in required_fields if field not in response_dict]
        if missing_fields:
            logger.error(f"[ê³„ì•½ì„œ ë¶„ì„] âŒ v2 í˜•ì‹ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing_fields}")
        else:
            logger.info(f"[ê³„ì•½ì„œ ë¶„ì„] âœ… v2 í˜•ì‹ ê²€ì¦ í†µê³¼")
        
        return analysis_result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ê³„ì•½ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ê³„ì•½ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)


@router.post("/compare-contracts", response_model=ContractComparisonResponseV2)
async def compare_contracts(
    request: ContractComparisonRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ê³„ì•½ì„œ ë²„ì „ ë¹„êµ (ì´ì „ vs ìƒˆ ê³„ì•½ì„œ)
    """
    try:
        storage_service = get_storage_service()
        
        # ì´ì „ ê³„ì•½ì„œ ì¡°íšŒ
        old_contract = await storage_service.get_contract_analysis(request.oldContractId)
        if not old_contract:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ì´ì „ ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.oldContractId}"
            )
        
        # ìƒˆ ê³„ì•½ì„œ ì¡°íšŒ
        new_contract = await storage_service.get_contract_analysis(request.newContractId)
        if not new_contract:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ìƒˆ ê³„ì•½ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.newContractId}"
            )
        
        # ë³€ê²½ëœ ì¡°í•­ ì°¾ê¸°
        changed_clauses = []
        old_clauses = {clause.get("id"): clause for clause in old_contract.get("clauses", [])}
        new_clauses = {clause.get("id"): clause for clause in new_contract.get("clauses", [])}
        
        # ìƒˆë¡œ ì¶”ê°€ëœ ì¡°í•­
        for clause_id, clause in new_clauses.items():
            if clause_id not in old_clauses:
                changed_clauses.append({
                    "type": "added",
                    "clauseId": clause_id,
                    "title": clause.get("title"),
                    "content": clause.get("content")
                })
        
        # ì‚­ì œëœ ì¡°í•­
        for clause_id, clause in old_clauses.items():
            if clause_id not in new_clauses:
                changed_clauses.append({
                    "type": "removed",
                    "clauseId": clause_id,
                    "title": clause.get("title"),
                    "content": clause.get("content")
                })
        
        # ìˆ˜ì •ëœ ì¡°í•­
        for clause_id in old_clauses.keys() & new_clauses.keys():
            old_clause = old_clauses[clause_id]
            new_clause = new_clauses[clause_id]
            if old_clause.get("content") != new_clause.get("content"):
                changed_clauses.append({
                    "type": "modified",
                    "clauseId": clause_id,
                    "title": new_clause.get("title"),
                    "oldContent": old_clause.get("content"),
                    "newContent": new_clause.get("content")
                })
        
        # ìœ„í—˜ë„ ë³€í™”
        risk_change = {
            "oldRiskScore": old_contract.get("riskScore", 0),
            "newRiskScore": new_contract.get("riskScore", 0),
            "oldRiskLevel": old_contract.get("riskLevel", "medium"),
            "newRiskLevel": new_contract.get("riskLevel", "medium"),
            "riskScoreDelta": new_contract.get("riskScore", 0) - old_contract.get("riskScore", 0)
        }
        
        # ë¹„êµ ìš”ì•½ ìƒì„±
        summary = f"ì´ {len(changed_clauses)}ê°œ ì¡°í•­ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. "
        summary += f"ìœ„í—˜ë„: {risk_change['oldRiskScore']:.1f} â†’ {risk_change['newRiskScore']:.1f} "
        summary += f"({risk_change['riskScoreDelta']:+.1f})"
        
        # ì‘ë‹µ ìƒì„±
        old_contract_response = ContractAnalysisResponseV2(**old_contract)
        new_contract_response = ContractAnalysisResponseV2(**new_contract)
        
        return ContractComparisonResponseV2(
            oldContract=old_contract_response,
            newContract=new_contract_response,
            changedClauses=changed_clauses,
            riskChange=risk_change,
            summary=summary
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ê³„ì•½ì„œ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ê³„ì•½ì„œ ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.post("/rewrite-clause", response_model=ClauseRewriteResponseV2)
async def rewrite_clause(
    request: ClauseRewriteRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ì¡°í•­ ìë™ ë¦¬ë¼ì´íŠ¸ (ìœ„í—˜ ì¡°í•­ì„ ì•ˆì „í•œ ë¬¸êµ¬ë¡œ ìˆ˜ì •)
    """
    try:
        rewrite_tool = RewriteTool()
        
        # issue ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìˆëŠ” ê²½ìš°)
        legal_basis = []
        if request.issueId:
            storage_service = get_storage_service()
            # issue ì •ë³´ ì¡°íšŒ (ê°„ë‹¨í•œ êµ¬í˜„)
            # ì‹¤ì œë¡œëŠ” issueë¥¼ ì¡°íšŒí•´ì„œ legalBasisë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
            pass
        
        # ë¦¬ë¼ì´íŠ¸ ì‹¤í–‰
        result = await rewrite_tool.execute(
            original_text=request.originalText,
            issue_id=request.issueId,
            legal_basis=legal_basis,
            contract_type="employment"  # ê¸°ë³¸ê°’
        )
        
        return ClauseRewriteResponseV2(
            originalText=result["originalText"],
            rewrittenText=result["rewrittenText"],
            explanation=result["explanation"],
            legalBasis=result["legalBasis"]
        )
        
    except Exception as e:
        logger.error(f"ì¡°í•­ ë¦¬ë¼ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì¡°í•­ ë¦¬ë¼ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.get("/contracts/history", response_model=List[dict])
async def get_contract_history(
    x_user_id: str = Header(..., alias="X-User-Id", description="ì‚¬ìš©ì ID"),
    limit: int = Query(20, ge=1, le=100, description="ì¡°íšŒ ê°œìˆ˜"),
    offset: int = Query(0, ge=0, description="ì˜¤í”„ì…‹"),
):
    """
    ì‚¬ìš©ìë³„ ê³„ì•½ì„œ ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    """
    try:
        storage_service = get_storage_service()
        history = await storage_service.get_user_contract_analyses(
            user_id=x_user_id,
            limit=limit,
            offset=offset,
        )
        return history
    except Exception as e:
        logger.error(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.get("/contracts/{doc_id}", response_model=ContractAnalysisResponseV2)
async def get_contract_analysis(
    doc_id: str,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ê³„ì•½ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    """
    logger.info(f"[ê³„ì•½ì„œ ì¡°íšŒ] doc_id={doc_id}, user_id={x_user_id} ì¡°íšŒ ì‹œì‘")
    
    # ì„ì‹œ IDì¸ ê²½ìš° ë©”ëª¨ë¦¬ì—ì„œë§Œ ì¡°íšŒ
    if doc_id.startswith("temp-"):
        logger.warning(f"[ê³„ì•½ì„œ ì¡°íšŒ] ì„ì‹œ ID ê°ì§€: {doc_id}, ë©”ëª¨ë¦¬ì—ì„œë§Œ ì¡°íšŒ")
        if doc_id in _contract_analyses:
            result = _contract_analyses[doc_id]
            contract_text_length = len(result.contractText) if result.contractText else 0
            logger.info(f"[ê³„ì•½ì„œ ì¡°íšŒ] ë©”ëª¨ë¦¬ì—ì„œ ì°¾ìŒ: doc_id={doc_id}, contractText ê¸¸ì´={contract_text_length}")
            return result
        else:
            logger.warning(f"[ê³„ì•½ì„œ ì¡°íšŒ] ë©”ëª¨ë¦¬ì—ì„œë„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {doc_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"ì„ì‹œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (doc_id: {doc_id})",
            )
    
    # DBì—ì„œ ì¡°íšŒ ì‹œë„
    try:
        storage_service = get_storage_service()
        result = await storage_service.get_contract_analysis(doc_id, user_id=x_user_id)
        if result:
            contract_text_length = len(result.get('contractText', '')) if result.get('contractText') else 0
            logger.info(f"[ê³„ì•½ì„œ ì¡°íšŒ] DBì—ì„œ ì°¾ìŒ: doc_id={doc_id}, user_id={x_user_id}, contractText ê¸¸ì´={contract_text_length}")
            return ContractAnalysisResponseV2(**result)
        else:
            logger.warning(f"[ê³„ì•½ì„œ ì¡°íšŒ] DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: doc_id={doc_id}, user_id={x_user_id}")
    except Exception as e:
        logger.error(f"[ê³„ì•½ì„œ ì¡°íšŒ] DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}", exc_info=True)
    
    # Fallback: ë©”ëª¨ë¦¬ì—ì„œ ì¡°íšŒ
    if doc_id in _contract_analyses:
        result = _contract_analyses[doc_id]
        contract_text_length = len(result.contractText) if result.contractText else 0
        logger.info(f"[ê³„ì•½ì„œ ì¡°íšŒ] ë©”ëª¨ë¦¬ì—ì„œ ì°¾ìŒ: doc_id={doc_id}, contractText ê¸¸ì´={contract_text_length}")
        return result
    
    logger.error(f"[ê³„ì•½ì„œ ì¡°íšŒ] ì–´ë””ì„œë„ ì°¾ì„ ìˆ˜ ì—†ìŒ: doc_id={doc_id}, user_id={x_user_id}")
    raise HTTPException(
        status_code=status.HTTP_404_NOT_FOUND,
        detail=f"ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (doc_id: {doc_id})",
    )


@router.post("/analyze-situation", response_model=SituationResponseV2)
async def analyze_situation(
    payload: SituationRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒí™© ì„¤ëª… + ë©”íƒ€ ì •ë³´ â†’ ë§ì¶¤í˜• ìƒë‹´ ë¶„ì„
    """
    # loggerë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì°¸ì¡° (ìŠ¤ì½”í”„ ë¬¸ì œ ë°©ì§€)
    import logging
    _logger = logging.getLogger(__name__)
    
    try:
        service = get_legal_service()
        
        # ê¸°ì¡´ analyze_situation_detailed ì‚¬ìš©
        result = await service.analyze_situation_detailed(
            category_hint=payload.category or "unknown",
            situation_text=payload.situation,
            summary=None,
            details=None,
            employment_type=payload.employmentType,
            work_period=payload.workPeriod,
            weekly_hours=None,
            is_probation=None,
            social_insurance=", ".join(payload.socialInsurance) if payload.socialInsurance else None,
        )
        
        # v2 ìŠ¤í™ì— ë§ì¶° ë³€í™˜
        risk_level = "low"
        if result["risk_score"] >= 70:
            risk_level = "high"
        elif result["risk_score"] >= 40:
            risk_level = "medium"
        
        # legalBasis ë³€í™˜ (status í•„ë“œ ë³´ì¡´)
        legal_basis = []
        for criteria in result.get("criteria", []):
            legal_basis.append({
                "title": criteria.get("name", ""),
                "snippet": criteria.get("reason", ""),
                "sourceType": "law",
                "status": criteria.get("status", "likely"),  # status í•„ë“œ ë³´ì¡´
            })
        
        # action_plan.stepsì—ì„œ checklistì™€ recommendations êµ¬ë¶„
        action_plan = result.get("action_plan", {})
        steps = action_plan.get("steps", [])
        
        # action_planì´ ë¹„ì–´ìˆìœ¼ë©´ summaryì—ì„œ "ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” í–‰ë™" ì„¹ì…˜ íŒŒì‹±
        if len(steps) == 0:
            summary_text = result.get("summary", "")
            # "## ğŸ¯ ì§€ê¸ˆ ë‹¹ì¥ í•  ìˆ˜ ìˆëŠ” í–‰ë™" ì„¹ì…˜ ì¶”ì¶œ
            action_section_match = re.search(
                r'##\s*ğŸ¯\s*ì§€ê¸ˆ\s*ë‹¹ì¥\s*í• \s*ìˆ˜\s*ìˆëŠ”\s*í–‰ë™\s*\n(.*?)(?=##|$)',
                summary_text,
                re.DOTALL | re.IGNORECASE
            )
            if action_section_match:
                action_content = action_section_match.group(1).strip()
                # "- " ë˜ëŠ” "* "ë¡œ ì‹œì‘í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ í•­ëª© ì¶”ì¶œ
                action_items = re.findall(r'[-*]\s*(.+?)(?=\n[-*]|\n##|$)', action_content, re.MULTILINE)
                action_items = [item.strip() for item in action_items if item.strip()]
                if action_items:
                    # ì²« ë²ˆì§¸ stepìœ¼ë¡œ ì¶”ê°€
                    steps = [{
                        "title": "ì¦‰ì‹œ ì¡°ì¹˜",
                        "items": action_items[:5]  # ìµœëŒ€ 5ê°œ
                    }]
        
        # checklist: ì²« ë²ˆì§¸ stepì˜ itemsë§Œ ì‚¬ìš©
        checklist = []
        if len(steps) > 0:
            checklist = steps[0].get("items", [])
        
        # recommendations: ë‚˜ë¨¸ì§€ stepsì˜ items ë³‘í•©
        recommendations = []
        for step in steps[1:]:
            recommendations.extend(step.get("items", []))
        
        # scripts ë³€í™˜
        scripts_data = result.get("scripts", {})
        scripts = None
        if scripts_data:
            scripts = ScriptsV2(
                toCompany=scripts_data.get("to_company"),
                toAdvisor=scripts_data.get("to_advisor"),
            )
        
        # relatedCases ë³€í™˜
        related_cases = []
        for case in result.get("related_cases", []):
            related_cases.append({
                "id": case.get("id", ""),
                "title": case.get("title", ""),
                "summary": case.get("summary", ""),
                "link": None,
            })
        
        # tags ì¶”ì¶œ (classified_type ê¸°ë°˜)
        tags = [result.get("classified_type", "unknown")]
        
        # DBì— ì €ì¥ (ë¹„ë™ê¸°, ì‹¤íŒ¨í•´ë„ ì‘ë‹µì€ ë°˜í™˜)
        situation_analysis_id = None
        try:
            storage_service = get_storage_service()
            analysis_summary = result.get("summary", "")
            situation_analysis_id = await storage_service.save_situation_analysis(
                situation=payload.situation,
                category=payload.category,
                employment_type=payload.employmentType,
                company_size=payload.companySize,
                work_period=payload.workPeriod,
                has_written_contract=payload.hasWrittenContract,
                social_insurance=payload.socialInsurance,
                risk_score=float(result["risk_score"]),
                risk_level=risk_level,
                analysis={
                    "summary": analysis_summary,
                    "legalBasis": legal_basis,
                    "recommendations": recommendations,
                },
                checklist=checklist,
                related_cases=related_cases,
                user_id=x_user_id,
                # situation_reports í†µí•© í•„ë“œ
                question=payload.situation,  # questionì€ situationê³¼ ë™ì¼
                answer=analysis_summary,  # answerëŠ” analysis.summary
                details=None,  # detailsëŠ” í˜„ì¬ ì œê³µë˜ì§€ ì•ŠìŒ
                category_hint=payload.category,  # category_hintëŠ” categoryì™€ ë™ì¼
                classified_type=result.get("classified_type", "unknown"),
            )
            _logger.info(f"ìƒí™© ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ (id: {situation_analysis_id}, user_id: {x_user_id})")
            
            # ëŒ€í™” ë©”ì‹œì§€ëŠ” íŠ¸ë¦¬ê±°ê°€ ìë™ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ ìˆ˜ë™ ì €ì¥ ë¶ˆí•„ìš”
            # íŠ¸ë¦¬ê±°ê°€ answer í•„ë“œë¥¼ sequence_number 0ìœ¼ë¡œ ì €ì¥í•¨
            # ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì €ì¥í•˜ê±°ë‚˜ ë³„ë„ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŒ
            # ì—¬ê¸°ì„œëŠ” íŠ¸ë¦¬ê±°ì— ì˜ì¡´í•˜ë¯€ë¡œ ìˆ˜ë™ ì €ì¥í•˜ì§€ ì•ŠìŒ
        except Exception as save_error:
            # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ë¶„ì„ ê²°ê³¼ëŠ” ë°˜í™˜
            _logger.warning(f"ìƒí™© ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨ (ì‘ë‹µì€ ì •ìƒ ë°˜í™˜): {str(save_error)}")
        
        # v2 ì‘ë‹µ ìƒì„± (DB ì €ì¥ í›„ ID í¬í•¨)
        response = SituationResponseV2(
            id=situation_analysis_id,  # DB ì €ì¥ í›„ ID í¬í•¨
            riskScore=float(result["risk_score"]),
            riskLevel=risk_level,
            tags=tags,
            analysis={
                "summary": result.get("summary", ""),
                "legalBasis": legal_basis,
                "recommendations": recommendations[:5],  # ìµœëŒ€ 5ê°œ
            },
            checklist=checklist,
            scripts=scripts,
            relatedCases=related_cases,
        )
        
        return response
    except Exception as e:
        _logger.error(f"ìƒí™© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ìƒí™© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.get("/situations/history", response_model=List[dict])
async def get_situation_history(
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
    limit: int = Query(20, ge=1, le=100, description="ì¡°íšŒ ê°œìˆ˜"),
    offset: int = Query(0, ge=0, description="ì˜¤í”„ì…‹"),
):
    """
    ì‚¬ìš©ìë³„ ìƒí™© ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    """
    try:
        if not x_user_id:
            logger.warning("ì‚¬ìš©ì IDê°€ ì œê³µë˜ì§€ ì•Šì•„ ë¹ˆ ë°°ì—´ ë°˜í™˜")
            return []
        
        storage_service = get_storage_service()
        history = await storage_service.get_user_situation_analyses(
            user_id=x_user_id,
            limit=limit,
            offset=offset,
        )
        return history
    except Exception as e:
        logger.error(f"ìƒí™© ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.get("/situations/{situation_id}", response_model=dict)
async def get_situation_analysis(
    situation_id: str,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    íŠ¹ì • ìƒí™© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    """
    try:
        storage_service = get_storage_service()
        analysis = await storage_service.get_situation_analysis(situation_id, x_user_id)
        if not analysis:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return analysis
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒí™© ë¶„ì„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.post("/conversations", response_model=dict)
async def save_conversation(
    payload: ConversationRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ìƒí™© ë¶„ì„ ëŒ€í™” ë©”ì‹œì§€ ì €ì¥
    """
    try:
        storage_service = get_storage_service()
        conversation_id = await storage_service.save_situation_conversation(
            report_id=payload.report_id,
            message=payload.message,
            sender_type=payload.sender_type,
            sequence_number=payload.sequence_number,
            user_id=x_user_id,
            metadata=payload.metadata,
        )
        return {"id": conversation_id, "success": True}
    except Exception as e:
        logger.error(f"ëŒ€í™” ë©”ì‹œì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ëŒ€í™” ë©”ì‹œì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.get("/conversations/{report_id}", response_model=List[dict])
async def get_conversations(
    report_id: str,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ìƒí™© ë¶„ì„ ëŒ€í™” ë©”ì‹œì§€ ì¡°íšŒ
    """
    try:
        storage_service = get_storage_service()
        conversations = await storage_service.get_situation_conversations(
            report_id=report_id,
            user_id=x_user_id,
        )
        return conversations
    except Exception as e:
        logger.error(f"ëŒ€í™” ë©”ì‹œì§€ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ëŒ€í™” ë©”ì‹œì§€ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )


@router.post("/chat", response_model=LegalChatResponseV2)
async def chat_with_contract(
    payload: LegalChatRequestV2,
    x_user_id: Optional[str] = Header(None, alias="X-User-Id", description="ì‚¬ìš©ì ID"),
):
    """
    ê³„ì•½ì„œ ê¸°ë°˜ ë²•ë¥  ìƒë‹´ ì±— (Dual RAG ì§€ì›)
    
    - ê³„ì•½ì„œ ë‚´ë¶€ ì²­í¬ ê²€ìƒ‰ (contract_chunks)
    - ì™¸ë¶€ ë²•ë ¹ ì²­í¬ ê²€ìƒ‰ (legal_chunks)
    - ì„ íƒëœ ì´ìŠˆ ê¸°ë°˜ boosting
    - êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„±
    """
    try:
        service = get_legal_service()
        
        # selected_issue ë³€í™˜ (í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ â†’ ë°±ì—”ë“œ í˜•ì‹)
        selected_issue = None
        if payload.selectedIssue:
            selected_issue = {
                "category": payload.selectedIssue.get("category"),
                "summary": payload.selectedIssue.get("summary"),
                "severity": payload.selectedIssue.get("severity"),
                "originalText": payload.selectedIssue.get("originalText"),
                "legalBasis": payload.selectedIssue.get("legalBasis", []),
            }
        
        # Dual RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
        result = await service.chat_with_context(
            query=payload.query,
            doc_ids=payload.docIds or [],
            selected_issue_id=payload.selectedIssueId,
            selected_issue=selected_issue,
            analysis_summary=payload.analysisSummary,
            risk_score=payload.riskScore,
            total_issues=payload.totalIssues,
            top_k=payload.topK or 8,
        )
        
        # used_chunks ë³€í™˜ (í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹)
        used_chunks_v2 = None
        if result.get("used_chunks"):
            used_chunks = result["used_chunks"]
            used_chunks_v2 = UsedChunksV2(
                contract=[
                    UsedChunkV2(
                        id=chunk.get("id"),
                        source_type="contract",
                        title=f"ì œ{chunk.get('article_number', '')}ì¡°",
                        content=chunk.get("content", "")[:500],
                        score=chunk.get("score"),
                    )
                    for chunk in used_chunks.get("contract", [])
                ],
                legal=[
                    UsedChunkV2(
                        id=chunk.get("id"),
                        source_type=chunk.get("source_type", "law"),
                        title=chunk.get("title", ""),
                        content=chunk.get("content", "")[:500],
                        score=chunk.get("score"),
                    )
                    for chunk in used_chunks.get("legal", [])
                ],
            )
        
        return LegalChatResponseV2(
            answer=result.get("answer", ""),
            markdown=result.get("markdown", result.get("answer", "")),
            query=result.get("query", payload.query),
            usedChunks=used_chunks_v2,
        )
    except Exception as e:
        logger.error(f"ë²•ë¥  ìƒë‹´ ì±— ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë²•ë¥  ìƒë‹´ ì±— ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )

