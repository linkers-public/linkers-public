# ë°±ì—”ë“œ ë¡œì§ ìƒì„¸ ì„¤ëª…

## ê°œìš”
ì´ ë¬¸ì„œëŠ” ë°±ì—”ë“œì˜ í•µì‹¬ ë¡œì§ì¸ ì²­í‚¹(Chunking), RAG êµ¬ì„±, ë²¡í„° ê²€ìƒ‰ì— ëŒ€í•´ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“„ 1. ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹ (Chunking)

### 1.1 ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
íŒŒì¼ ì—…ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ì²­í¬ ë¶„í•  â†’ ì„ë² ë”© ìƒì„± â†’ ë²¡í„° ì €ì¥
```

### 1.2 í…ìŠ¤íŠ¸ ì¶”ì¶œ

**ì§€ì› íŒŒì¼ í˜•ì‹:**
- PDF: PyMuPDF â†’ pdfplumber â†’ pypdf â†’ OCR (ìˆœì°¨ ì‹œë„)
- HWP/HWPX/HWPS: XML íŒŒì‹± ë˜ëŠ” ì™¸ë¶€ ë³€í™˜ ì„œë¹„ìŠ¤
- HTML: HTML íŒŒì„œë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- TXT: ì§ì ‘ ì½ê¸°

**ì½”ë“œ ìœ„ì¹˜:** `core/document_processor_v2.py`

```python
# PDF ì²˜ë¦¬ ì˜ˆì‹œ
def pdf_to_text(self, pdf_path: str) -> str:
    # 1. PyMuPDF ì‹œë„ (ê°€ì¥ ê°•ë ¥)
    # 2. pdfplumber ì‹œë„ (í‘œ ì²˜ë¦¬ì— ì¢‹ìŒ)
    # 3. pypdf ì‹œë„ (ê¸°ë³¸ ë°©ë²•)
    # 4. OCR ì‹œë„ (ìŠ¤ìº”ëœ PDFìš©)
```

### 1.3 ì²­í‚¹ (Chunking) ì „ëµ

**ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜:**
- **ë°©ì‹**: Recursive Character Text Splitter (ê°„ë‹¨í•œ êµ¬í˜„)
- **ì²­í¬ í¬ê¸°**: ê¸°ë³¸ 1000ì (`CHUNK_SIZE` í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì •)
- **ì˜¤ë²„ë©**: ê¸°ë³¸ 200ì (`CHUNK_OVERLAP` í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì •)
- **êµ¬ë¶„ì ìš°ì„ ìˆœìœ„**: `["\n\n", "\n", ". ", " ", ""]`

**ì²­í‚¹ ê³¼ì •:**

```python
# core/document_processor_v2.pyì˜ SimpleTextSplitter

1. í…ìŠ¤íŠ¸ë¥¼ chunk_size ë‹¨ìœ„ë¡œ ë¶„í• 
2. ê° ì²­í¬ì˜ ëì—ì„œ êµ¬ë¶„ì(ì¤„ë°”ê¿ˆ, ë¬¸ì¥ ë ë“±)ë¥¼ ì°¾ì•„ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• 
3. ì˜¤ë²„ë©ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ì²­í¬ ì‹œì‘ ìœ„ì¹˜ ê²°ì •
4. ë¹ˆ ì²­í¬ ì œê±° ë° ì •ì œ
```

**ì²­í‚¹ ì˜ˆì‹œ:**
```
ì›ë³¸ í…ìŠ¤íŠ¸ (3000ì)
â†“
ì²­í¬ 1: 0-1000ì (êµ¬ë¶„ìì—ì„œ ë¶„í• )
ì²­í¬ 2: 800-1800ì (200ì ì˜¤ë²„ë©)
ì²­í¬ 3: 1600-2600ì (200ì ì˜¤ë²„ë©)
ì²­í¬ 4: 2400-3000ì (ë§ˆì§€ë§‰)
```

**ì²­í‚¹ ë©”íƒ€ë°ì´í„°:**
ê° ì²­í¬ëŠ” ë‹¤ìŒ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- `chunk_index`: ì²­í¬ ìˆœì„œ (0ë¶€í„° ì‹œì‘)
- `chunk_size`: ì²­í¬ ê¸¸ì´
- `total_chunks`: ì „ì²´ ì²­í¬ ê°œìˆ˜
- `source`: ë¬¸ì„œ ì¶œì²˜
- `external_id`: ì™¸ë¶€ ID
- `title`: ë¬¸ì„œ ì œëª©

### 1.4 í…ìŠ¤íŠ¸ ì •ì œ

```python
def _clean_text(self, text: str) -> str:
    # ì¤‘ë³µ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì ë§Œ ìœ ì§€)
    text = re.sub(r'[^\w\sê°€-í£.,()%\-:/]', '', text)
    return text.strip()
```

## ğŸ” 2. RAG (Retrieval-Augmented Generation) êµ¬ì„±

### 2.1 RAG ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‚¬ìš©ì ì¿¼ë¦¬     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± â”‚ (sentence-transformers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ â”‚ (Supabase pgvector)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê´€ë ¨ ë¬¸ì„œ ì²­í¬   â”‚ (Top-K ê²€ìƒ‰)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM ë‹µë³€ ìƒì„±    â”‚ (Ollama/OpenAI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 RAG íŒŒì´í”„ë¼ì¸ ìƒì„¸

**ì½”ë“œ ìœ„ì¹˜:** `core/orchestrator_v2.py`

#### ë‹¨ê³„ 1: ë¬¸ì„œ ì¸ì… ë° ì €ì¥
```python
def process_announcement(meta, text):
    # 1. ì¤‘ë³µ/ë²„ì „ íŒë³„ (content_hash)
    announcement_id = store.upsert_announcement(meta, text)
    
    # 2. í…ìŠ¤íŠ¸ â†’ ì²­í¬ ë¶„í• 
    chunks = processor.to_chunks(text, base_meta)
    
    # 3. ì²­í¬ â†’ ì„ë² ë”© ìƒì„±
    embeddings = generator.embed(chunk_texts)
    
    # 4. ë²¡í„° ì €ì¥ (pgvector)
    store.bulk_upsert_chunks(announcement_id, chunk_payload)
    
    # 5. LLM êµ¬ì¡°í™” ë¶„ì„
    analysis_result = generator.analyze_announcement(text, seed_meta)
    
    # 6. ë¶„ì„ ê²°ê³¼ ì €ì¥
    store.save_analysis(announcement_id, analysis_result, score)
```

#### ë‹¨ê³„ 2: ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
```python
def search_similar_announcements(query, top_k=5):
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = generator.embed_one(query)
    
    # 2. ë²¡í„° ê²€ìƒ‰
    results = store.search_similar_chunks(
        query_embedding,
        top_k=top_k,
        filters=filters
    )
    
    return results
```

### 2.3 ì„ë² ë”© ìƒì„±

**ì„ë² ë”© ëª¨ë¸:**
- **ë¡œì»¬ ì„ë² ë”©**: `sentence-transformers` ì‚¬ìš©
- **ê¸°ë³¸ ëª¨ë¸**: `BAAI/bge-small-en-v1.5` (384ì°¨ì›)
- **ë¬¸ì„œ ì„ë² ë”©**: `BAAI/bge-m3` (1024ì°¨ì›, ë‹¤êµ­ì–´ ì§€ì›)
- **ê¸°ì—… ì„ë² ë”©**: `BAAI/bge-small-en-v1.5` (384ì°¨ì›, ë¹ ë¦„)

**ì½”ë“œ ìœ„ì¹˜:** `core/generator_v2.py`

```python
def embed(self, texts: List[str]) -> List[List[float]]:
    # sentence-transformers ì‚¬ìš©
    model = SentenceTransformer(settings.local_embedding_model)
    embeddings = model.encode(texts, convert_to_numpy=True)
    return embeddings.tolist()
```

### 2.4 ë²¡í„° ì €ì¥

**ì €ì¥ì†Œ:**
- **Supabase pgvector**: PostgreSQLì˜ pgvector í™•ì¥ ì‚¬ìš©
- **í…Œì´ë¸” êµ¬ì¡°:**
  - `announcement_chunks`: ê³µê³  ì²­í¬ ë° ì„ë² ë”©
  - `legal_chunks`: ë²•ë¥  ë¬¸ì„œ ì²­í¬ ë° ì„ë² ë”©
  - `team_embeddings`: íŒ€ ì„ë² ë”©

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py`

```python
def bulk_upsert_chunks(announcement_id, chunks):
    payload = [{
        "announcement_id": announcement_id,
        "chunk_index": c["chunk_index"],
        "content": c["content"],
        "embedding": c["embedding"],  # float[] ë°°ì—´
        "metadata": c.get("metadata", {})
    } for c in chunks]
    
    sb.table("announcement_chunks").insert(payload).execute()
```

## ğŸ” 3. ë²¡í„° ê²€ìƒ‰ (Vector Search)

### 3.1 ê²€ìƒ‰ ë°©ì‹

**ê²€ìƒ‰ì€ ì¿¼ë¦¬ ì¤‘ì‹¬ (Query-based)ì…ë‹ˆë‹¤.**

1. **ì‚¬ìš©ì ì¿¼ë¦¬** â†’ **ì„ë² ë”© ë²¡í„° ë³€í™˜**
2. **ì„ë² ë”© ë²¡í„°** â†’ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°**
3. **ìœ ì‚¬ë„ ìˆœ ì •ë ¬** â†’ **Top-K ê²°ê³¼ ë°˜í™˜**

### 3.2 ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py`

#### ë°©ë²• 1: Supabase RPC í•¨ìˆ˜ ì‚¬ìš© (ê¶Œì¥)

```python
def search_similar_chunks(query_embedding, top_k=5, filters=None):
    rpc_params = {
        "query_embedding": query_embedding,  # float[] ë°°ì—´
        "match_threshold": 0.7,  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
        "match_count": top_k,
        "filters": filters or {}
    }
    
    result = sb.rpc("match_announcement_chunks", rpc_params).execute()
    return result.data
```

**Supabase RPC í•¨ìˆ˜ ì˜ˆì‹œ (SQL):**
```sql
CREATE OR REPLACE FUNCTION match_announcement_chunks(
    query_embedding vector(384),
    match_threshold float,
    match_count int
)
RETURNS TABLE (
    id uuid,
    content text,
    similarity float,
    metadata jsonb
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        ac.id,
        ac.content,
        1 - (ac.embedding <=> query_embedding) as similarity,
        ac.metadata
    FROM announcement_chunks ac
    WHERE 1 - (ac.embedding <=> query_embedding) > match_threshold
    ORDER BY ac.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

#### ë°©ë²• 2: í´ë¼ì´ì–¸íŠ¸ ì¸¡ ê³„ì‚° (Fallback)

RPC í•¨ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°, ëª¨ë“  ì²­í¬ë¥¼ ê°€ì ¸ì™€ì„œ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìœ ì‚¬ë„ ê³„ì‚°:

```python
# ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
chunks = sb.table("announcement_chunks").select("*").execute()

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
import numpy as np
query_vec = np.array(query_embedding, dtype=np.float32)

results = []
for chunk in chunks:
    chunk_vec = np.array(chunk["embedding"], dtype=np.float32)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = dot product / (norm1 * norm2)
    similarity = np.dot(query_vec, chunk_vec) / (
        np.linalg.norm(query_vec) * np.linalg.norm(chunk_vec)
    )
    
    if similarity > threshold:
        results.append({
            "id": chunk["id"],
            "content": chunk["content"],
            "similarity": float(similarity),
            "metadata": chunk["metadata"]
        })

# ìœ ì‚¬ë„ ìˆœ ì •ë ¬
results.sort(key=lambda x: x["similarity"], reverse=True)
return results[:top_k]
```

### 3.3 ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Cosine Similarity)

**ê³µì‹:**
```
similarity = (A Â· B) / (||A|| Ã— ||B||)
```

- `A Â· B`: ë‘ ë²¡í„°ì˜ ë‚´ì  (dot product)
- `||A||`: ë²¡í„° Aì˜ í¬ê¸° (norm)
- `||B||`: ë²¡í„° Bì˜ í¬ê¸° (norm)
- ê²°ê³¼ê°’: -1 ~ 1 (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)

**pgvector ì—°ì‚°ì:**
- `<=>`: ì½”ì‚¬ì¸ ê±°ë¦¬ (1 - similarity)
- `<=>` ê°’ì´ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨

### 3.4 ê²€ìƒ‰ ìµœì í™”

#### ì¸ë±ì‹±
```sql
-- ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (IVFFlat)
CREATE INDEX ON announcement_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

#### í•„í„°ë§
```python
# ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
filters = {
    "source": "ë‚˜ë¼ì¥í„°",
    "budget_min": 10000000
}

# Supabase ì¿¼ë¦¬
result = sb.table("announcement_chunks")\
    .select("*")\
    .eq("metadata->>source", filters["source"])\
    .gte("metadata->>budget_min", filters["budget_min"])\
    .execute()
```

### 3.5 ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py::search_similar_legal_chunks`

ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ì€ ë™ì¼í•œ ë²¡í„° ê²€ìƒ‰ ë°©ì‹ì„ ì‚¬ìš©í•˜ì§€ë§Œ, `legal_chunks` í…Œì´ë¸”ì„ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤:

```python
def search_similar_legal_chunks(
    query_embedding: List[float],
    top_k: int = 5,
    filters: Optional[Dict] = None
):
    # source_type í•„í„°ë§ (law, manual, case ë“±)
    query = sb.table("legal_chunks").select("*")
    
    if filters and "source_type" in filters:
        query = query.eq("source_type", filters["source_type"])
    
    chunks = query.execute().data
    
    # í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìœ ì‚¬ë„ ê³„ì‚°
    # (RPC í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
    ...
```

## ğŸ”„ 4. ì „ì²´ í”Œë¡œìš° ì˜ˆì‹œ

### 4.1 ê³µê³  ì—…ë¡œë“œ ë° ì¸ë±ì‹±

```
1. íŒŒì¼ ì—…ë¡œë“œ (PDF)
   â†“
2. í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)
   "ê³µê³  ë‚´ìš© í…ìŠ¤íŠ¸..."
   â†“
3. ì²­í¬ ë¶„í•  (1000ìì”©, 200ì ì˜¤ë²„ë©)
   - ì²­í¬ 1: "ê³µê³  ë‚´ìš© í…ìŠ¤íŠ¸..." (0-1000ì)
   - ì²­í¬ 2: "...í…ìŠ¤íŠ¸..." (800-1800ì)
   - ì²­í¬ 3: "...ë‚´ìš©..." (1600-2600ì)
   â†“
4. ì„ë² ë”© ìƒì„± (sentence-transformers)
   - ì²­í¬ 1 â†’ [0.1, 0.2, ..., 0.9] (384ì°¨ì›)
   - ì²­í¬ 2 â†’ [0.2, 0.1, ..., 0.8] (384ì°¨ì›)
   - ì²­í¬ 3 â†’ [0.3, 0.2, ..., 0.7] (384ì°¨ì›)
   â†“
5. ë²¡í„° ì €ì¥ (Supabase)
   INSERT INTO announcement_chunks (embedding, content, ...)
   â†“
6. LLM ë¶„ì„ (Ollama)
   - í”„ë¡œì íŠ¸ëª…, ì˜ˆì‚°, ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ
   â†“
7. ë¶„ì„ ê²°ê³¼ ì €ì¥
   INSERT INTO announcement_analysis (result, ...)
```

### 4.2 ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±

```
1. ì‚¬ìš©ì ì¿¼ë¦¬
   "React ê°œë°œìê°€ í•„ìš”í•œ ê³µê³  ì°¾ì•„ì¤˜"
   â†“
2. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
   "React ê°œë°œìê°€ í•„ìš”í•œ ê³µê³  ì°¾ì•„ì¤˜" 
   â†’ [0.15, 0.25, ..., 0.85] (384ì°¨ì›)
   â†“
3. ë²¡í„° ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
   - ì²­í¬ A: similarity = 0.92
   - ì²­í¬ B: similarity = 0.88
   - ì²­í¬ C: similarity = 0.85
   â†“
4. Top-K ê²°ê³¼ ì„ íƒ (top_k=5)
   [ì²­í¬ A, ì²­í¬ B, ì²­í¬ C, ...]
   â†“
5. LLM ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
   "ê´€ë ¨ ë¬¸ì„œ:
   - ì²­í¬ A: React ê°œë°œì ëª¨ì§‘...
   - ì²­í¬ B: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ...
   ..."
   â†“
6. LLM ë‹µë³€ ìƒì„± (Ollama)
   "ë‹¤ìŒ ê³µê³ ë“¤ì´ React ê°œë°œìë¥¼ ëª¨ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤:
   1. [ê³µê³ ëª…] - React, TypeScript ê²½ë ¥ 3ë…„ ì´ìƒ
   ..."
```

## ğŸ“Š 5. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### 5.1 ì£¼ìš” í…Œì´ë¸”

#### `announcements`
- `id`: UUID (PK)
- `source`: ì¶œì²˜
- `external_id`: ì™¸ë¶€ ì‹œìŠ¤í…œ ID
- `title`: ì œëª©
- `version`: ë²„ì „ ë²ˆí˜¸
- `content_hash`: ë‚´ìš© í•´ì‹œ (ì¤‘ë³µ ê°ì§€)

#### `announcement_chunks`
- `id`: UUID (PK)
- `announcement_id`: ê³µê³  ID (FK)
- `chunk_index`: ì²­í¬ ìˆœì„œ
- `content`: ì²­í¬ í…ìŠ¤íŠ¸
- `embedding`: vector(384) - ì„ë² ë”© ë²¡í„°
- `metadata`: JSONB - ë©”íƒ€ë°ì´í„°

#### `legal_chunks`
- `id`: UUID (PK)
- `external_id`: ì™¸ë¶€ ë¬¸ì„œ ID
- `source_type`: ë¬¸ì„œ íƒ€ì… (law, manual, case)
- `title`: ë¬¸ì„œ ì œëª©
- `content`: ì²­í¬ í…ìŠ¤íŠ¸
- `embedding`: vector(384) - ì„ë² ë”© ë²¡í„°
- `metadata`: JSONB - ë©”íƒ€ë°ì´í„°

### 5.2 ì¸ë±ìŠ¤

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ (IVFFlat)
CREATE INDEX announcement_chunks_embedding_idx 
ON announcement_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤
CREATE INDEX announcement_chunks_metadata_idx 
ON announcement_chunks 
USING gin (metadata);
```

## ğŸ¯ 6. ê²€ìƒ‰ ì „ëµ ë¹„êµ

### 6.1 ë²¡í„° ê²€ìƒ‰ (Vector Search)
- **ë°©ì‹**: ì„ë² ë”© ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
- **ì¥ì **: ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰, ë™ì˜ì–´ ì²˜ë¦¬ ê°€ëŠ¥
- **ë‹¨ì **: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì€ ì•½í•¨

### 6.2 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)
- **ë°©ì‹**: ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)
- **ì¥ì **: ì˜ë¯¸ ê²€ìƒ‰ + ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
- **êµ¬í˜„**: `core/tools/vector_search_tool.py`

### 6.3 MMR ì¬ë­í‚¹ (Maximal Marginal Relevance)
- **ë°©ì‹**: ìœ ì‚¬ë„ + ë‹¤ì–‘ì„± ê³ ë ¤
- **ì¥ì **: ì¤‘ë³µ ê²°ê³¼ ì œê±°, ë‹¤ì–‘í•œ ê²°ê³¼ ì œê³µ
- **êµ¬í˜„**: `core/tools/vector_search_tool.py`

## ğŸ”§ 7. ì„¤ì • ë° íŠœë‹

### 7.1 ì²­í‚¹ íŒŒë¼ë¯¸í„°

```env
# .env íŒŒì¼
CHUNK_SIZE=1000      # ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)
CHUNK_OVERLAP=200    # ì˜¤ë²„ë© í¬ê¸° (ë¬¸ì ìˆ˜)
```

**ê¶Œì¥ê°’:**
- **ì§§ì€ ë¬¸ì„œ**: `CHUNK_SIZE=500, CHUNK_OVERLAP=100`
- **ê¸´ ë¬¸ì„œ**: `CHUNK_SIZE=2000, CHUNK_OVERLAP=400`
- **ë²•ë¥  ë¬¸ì„œ**: `CHUNK_SIZE=1500, CHUNK_OVERLAP=300`

### 7.2 ê²€ìƒ‰ íŒŒë¼ë¯¸í„°

```python
# ê²€ìƒ‰ ì‹œ
top_k = 5              # ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
match_threshold = 0.7  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
```

**ê¶Œì¥ê°’:**
- **ì¼ë°˜ ê²€ìƒ‰**: `top_k=5, match_threshold=0.7`
- **ì •ë°€ ê²€ìƒ‰**: `top_k=3, match_threshold=0.85`
- **ê´‘ë²”ìœ„ ê²€ìƒ‰**: `top_k=10, match_threshold=0.6`

### 7.3 ì„ë² ë”© ëª¨ë¸ ì„ íƒ

```env
# ë¬¸ì„œ ì„ë² ë”© (ê³µê³ ë¬¸, ê³„ì•½ì„œ)
LOCAL_EMBEDDING_MODEL=BAAI/bge-m3          # 1024ì°¨ì›, ë‹¤êµ­ì–´

# ê¸°ì—… ì„ë² ë”© (íŒ€, ê¸°ì—…)
COMPANY_EMBED_MODEL=BAAI/bge-small-en-v1.5  # 384ì°¨ì›, ë¹ ë¦„
```

## ğŸ“ 8. ì£¼ìš” ì½”ë“œ ì°¸ì¡°

### 8.1 ì²­í‚¹
- `core/document_processor_v2.py::to_chunks()` - ì²­í¬ ë¶„í• 
- `core/document_processor_v2.py::SimpleTextSplitter` - ë¶„í•  ì•Œê³ ë¦¬ì¦˜

### 8.2 ì„ë² ë”©
- `core/generator_v2.py::embed()` - ë°°ì¹˜ ì„ë² ë”©
- `core/generator_v2.py::embed_one()` - ë‹¨ì¼ ì„ë² ë”©

### 8.3 ë²¡í„° ê²€ìƒ‰
- `core/supabase_vector_store.py::search_similar_chunks()` - ê³µê³  ê²€ìƒ‰
- `core/supabase_vector_store.py::search_similar_legal_chunks()` - ë²•ë¥  ê²€ìƒ‰
- `core/orchestrator_v2.py::search_similar_announcements()` - ê²€ìƒ‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### 8.4 RAG íŒŒì´í”„ë¼ì¸
- `core/orchestrator_v2.py::process_announcement()` - ì „ì²´ íŒŒì´í”„ë¼ì¸
- `core/legal_rag_service.py::analyze_contract()` - ê³„ì•½ì„œ ë¶„ì„ RAG

## ğŸš€ 9. ì„±ëŠ¥ ìµœì í™”

### 9.1 ë²¡í„° ì¸ë±ìŠ¤
- IVFFlat ì¸ë±ìŠ¤ ì‚¬ìš© (ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰)
- `lists` íŒŒë¼ë¯¸í„° ì¡°ì • (100-1000 ê¶Œì¥)

### 9.2 ë°°ì¹˜ ì²˜ë¦¬
- ì„ë² ë”© ìƒì„± ì‹œ ë°°ì¹˜ ì²˜ë¦¬ (`embed()` ë©”ì„œë“œ)
- ë²¡í„° ì €ì¥ ì‹œ ì¼ê´„ ì‚½ì… (`bulk_upsert_chunks()`)

### 9.3 ìºì‹±
- ì„ë² ë”© ëª¨ë¸ ì§€ì—° ë¡œë“œ (ì‹±ê¸€í†¤ íŒ¨í„´)
- Supabase í´ë¼ì´ì–¸íŠ¸ ì§€ì—° ì´ˆê¸°í™”

## ğŸ“š ì°¸ê³  ìë£Œ

- [Supabase pgvector ë¬¸ì„œ](https://supabase.com/docs/guides/ai/vector-columns)
- [sentence-transformers ë¬¸ì„œ](https://www.sbert.net/)
- [LangChain RAG ê°€ì´ë“œ](https://python.langchain.com/docs/use_cases/question_answering/)

