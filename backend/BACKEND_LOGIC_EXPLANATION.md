# ë°±ì—”ë“œ ë¡œì§ ìƒì„¸ ì„¤ëª…

## ê°œìš”
ì´ ë¬¸ì„œëŠ” ë°±ì—”ë“œì˜ í•µì‹¬ ë¡œì§ì¸ ì²­í‚¹(Chunking), RAG êµ¬ì„±, ë²¡í„° ê²€ìƒ‰ì— ëŒ€í•´ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

## âš ï¸ ì¤‘ìš” ì‚¬í•­

**í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” ë²•ë¥  ë¦¬ìŠ¤í¬ ë¶„ì„ì— ì§‘ì¤‘í•˜ê³  ìˆìœ¼ë©°, ê³µê³  ê´€ë ¨ ê¸°ëŠ¥ì€ ë ˆê±°ì‹œì…ë‹ˆë‹¤.**

- âœ… **í˜„ì¬ ì‚¬ìš© ì¤‘**: `legal_chunks` í…Œì´ë¸” (ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰)
- âš ï¸ **ë ˆê±°ì‹œ (ì‚¬ìš© ì•ˆ í•¨)**: `announcement_chunks` í…Œì´ë¸” (ê³µê³  ê²€ìƒ‰)
- âœ… **í˜„ì¬ ì‚¬ìš© ì¤‘**: `contract_analyses`, `contract_issues` í…Œì´ë¸” (ê³„ì•½ì„œ ë¶„ì„ ê²°ê³¼)

## ğŸ“„ 1. ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹ (Chunking)

### 1.1 ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
íŒŒì¼ ì—…ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ì²­í¬ ë¶„í•  â†’ ì„ë² ë”© ìƒì„± â†’ ë²¡í„° ì €ì¥
```

### 1.2 í…ìŠ¤íŠ¸ ì¶”ì¶œ

**ì§€ì› íŒŒì¼ í˜•ì‹:**
- PDF: PyMuPDF â†’ pdfplumber â†’ pypdf â†’ OCR (ìˆœì°¨ ì‹œë„)
- HWP/HWPX/HWPS: XML íŒŒì‹± ë˜ëŠ” ì™¸ë¶€ ë³€í™˜ ì„œë¹„ìŠ¤
- HTML: HTML íŒŒì„œë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
- TXT: ì§ì ‘ ì½ê¸°

**ì½”ë“œ ìœ„ì¹˜:** `core/document_processor_v2.py`

```python
# PDF ì²˜ë¦¬ ì˜ˆì‹œ
def pdf_to_text(self, pdf_path: str) -> str:
    # 1. PyMuPDF ì‹œë„ (ê°€ì¥ ê°•ë ¥)
    # 2. pdfplumber ì‹œë„ (í‘œ ì²˜ë¦¬ì— ì¢‹ìŒ)
    # 3. pypdf ì‹œë„ (ê¸°ë³¸ ë°©ë²•)
    # 4. OCR ì‹œë„ (ìŠ¤ìº”ëœ PDFìš©)
```

### 1.3 ì²­í‚¹ (Chunking) ì „ëµ

**ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜:**
- **ë°©ì‹**: Recursive Character Text Splitter (ê°„ë‹¨í•œ êµ¬í˜„)
- **ì²­í¬ í¬ê¸°**: ê¸°ë³¸ 1000ì (`CHUNK_SIZE` í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì •)
- **ì˜¤ë²„ë©**: ê¸°ë³¸ 200ì (`CHUNK_OVERLAP` í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì •)
- **êµ¬ë¶„ì ìš°ì„ ìˆœìœ„**: `["\n\n", "\n", ". ", " ", ""]`

**ì²­í‚¹ ê³¼ì •:**

```python
# core/document_processor_v2.pyì˜ SimpleTextSplitter

1. í…ìŠ¤íŠ¸ë¥¼ chunk_size ë‹¨ìœ„ë¡œ ë¶„í• 
2. ê° ì²­í¬ì˜ ëì—ì„œ êµ¬ë¶„ì(ì¤„ë°”ê¿ˆ, ë¬¸ì¥ ë ë“±)ë¥¼ ì°¾ì•„ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• 
3. ì˜¤ë²„ë©ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ì²­í¬ ì‹œì‘ ìœ„ì¹˜ ê²°ì •
4. ë¹ˆ ì²­í¬ ì œê±° ë° ì •ì œ
```

**ì²­í‚¹ ì˜ˆì‹œ:**
```
ì›ë³¸ í…ìŠ¤íŠ¸ (3000ì)
â†“
ì²­í¬ 1: 0-1000ì (êµ¬ë¶„ìì—ì„œ ë¶„í• )
ì²­í¬ 2: 800-1800ì (200ì ì˜¤ë²„ë©)
ì²­í¬ 3: 1600-2600ì (200ì ì˜¤ë²„ë©)
ì²­í¬ 4: 2400-3000ì (ë§ˆì§€ë§‰)
```

**ì²­í‚¹ ë©”íƒ€ë°ì´í„°:**
ê° ì²­í¬ëŠ” ë‹¤ìŒ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- `chunk_index`: ì²­í¬ ìˆœì„œ (0ë¶€í„° ì‹œì‘)
- `chunk_size`: ì²­í¬ ê¸¸ì´
- `total_chunks`: ì „ì²´ ì²­í¬ ê°œìˆ˜
- `source`: ë¬¸ì„œ ì¶œì²˜
- `external_id`: ì™¸ë¶€ ID
- `title`: ë¬¸ì„œ ì œëª©

### 1.4 í…ìŠ¤íŠ¸ ì •ì œ

```python
def _clean_text(self, text: str) -> str:
    # ì¤‘ë³µ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê¸°ë³¸ êµ¬ë‘ì ë§Œ ìœ ì§€)
    text = re.sub(r'[^\w\sê°€-í£.,()%\-:/]', '', text)
    return text.strip()
```

## ğŸ” 2. RAG (Retrieval-Augmented Generation) êµ¬ì„±

### 2.1 RAG ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì‚¬ìš©ì ì¿¼ë¦¬     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± â”‚ (sentence-transformers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ â”‚ (Supabase pgvector)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê´€ë ¨ ë¬¸ì„œ ì²­í¬   â”‚ (Top-K ê²€ìƒ‰)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM ë‹µë³€ ìƒì„±    â”‚ (Ollama/OpenAI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 RAG íŒŒì´í”„ë¼ì¸ ìƒì„¸

**ì½”ë“œ ìœ„ì¹˜:** `core/orchestrator_v2.py`

#### ë‹¨ê³„ 1: ë¬¸ì„œ ì¸ì… ë° ì €ì¥
```python
def process_announcement(meta, text):
    # 1. ì¤‘ë³µ/ë²„ì „ íŒë³„ (content_hash)
    announcement_id = store.upsert_announcement(meta, text)
    
    # 2. í…ìŠ¤íŠ¸ â†’ ì²­í¬ ë¶„í• 
    chunks = processor.to_chunks(text, base_meta)
    
    # 3. ì²­í¬ â†’ ì„ë² ë”© ìƒì„±
    embeddings = generator.embed(chunk_texts)
    
    # 4. ë²¡í„° ì €ì¥ (pgvector)
    store.bulk_upsert_chunks(announcement_id, chunk_payload)
    
    # 5. LLM êµ¬ì¡°í™” ë¶„ì„
    analysis_result = generator.analyze_announcement(text, seed_meta)
    
    # 6. ë¶„ì„ ê²°ê³¼ ì €ì¥
    store.save_analysis(announcement_id, analysis_result, score)
```

#### ë‹¨ê³„ 2: ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
```python
def search_similar_announcements(query, top_k=5):
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = generator.embed_one(query)
    
    # 2. ë²¡í„° ê²€ìƒ‰
    results = store.search_similar_chunks(
        query_embedding,
        top_k=top_k,
        filters=filters
    )
    
    return results
```

### 2.3 ì„ë² ë”© ìƒì„±

**ì„ë² ë”© ëª¨ë¸:**
- **ë¡œì»¬ ì„ë² ë”©**: `sentence-transformers` ì‚¬ìš©
- **ê¸°ë³¸ ëª¨ë¸**: `BAAI/bge-small-en-v1.5` (384ì°¨ì›)
- **ë¬¸ì„œ ì„ë² ë”©**: `BAAI/bge-m3` (1024ì°¨ì›, ë‹¤êµ­ì–´ ì§€ì›)
- **ê¸°ì—… ì„ë² ë”©**: `BAAI/bge-small-en-v1.5` (384ì°¨ì›, ë¹ ë¦„)

**ì½”ë“œ ìœ„ì¹˜:** `core/generator_v2.py`

```python
def embed(self, texts: List[str]) -> List[List[float]]:
    # sentence-transformers ì‚¬ìš©
    model = SentenceTransformer(settings.local_embedding_model)
    embeddings = model.encode(texts, convert_to_numpy=True)
    return embeddings.tolist()
```

### 2.4 ë²¡í„° ì €ì¥

**ì €ì¥ì†Œ:**
- **Supabase pgvector**: PostgreSQLì˜ pgvector í™•ì¥ ì‚¬ìš©
- **í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í…Œì´ë¸”:**
  - âœ… `legal_chunks`: ë²•ë¥  ë¬¸ì„œ ì²­í¬ ë° ì„ë² ë”© (í˜„ì¬ ì‚¬ìš© ì¤‘)
  - âš ï¸ `announcement_chunks`: ê³µê³  ì²­í¬ ë° ì„ë² ë”© (ë ˆê±°ì‹œ, ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
  - âš ï¸ `team_embeddings`: íŒ€ ì„ë² ë”© (ë ˆê±°ì‹œ, ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py`

**ë²•ë¥  ë¬¸ì„œ ì²­í¬ ì €ì¥ ì˜ˆì‹œ:**
```python
# legal_chunks í…Œì´ë¸”ì— ì €ì¥
def upsert_legal_chunks(chunks):
    payload = [{
        "external_id": chunk["external_id"],
        "source_type": chunk["source_type"],  # "law", "manual", "case"
        "title": chunk["title"],
        "content": chunk["content"],
        "embedding": chunk["embedding"],  # float[] ë°°ì—´ (384ì°¨ì›)
        "metadata": chunk.get("metadata", {}),
        "chunk_index": chunk.get("chunk_index", 0)
    } for chunk in chunks]
    
    sb.table("legal_chunks").upsert(payload, on_conflict="external_id,chunk_index").execute()
```

**ë ˆê±°ì‹œ ì½”ë“œ (ì°¸ê³ ìš©):**
```python
# announcement_chunksëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
def bulk_upsert_chunks(announcement_id, chunks):  # ë ˆê±°ì‹œ
    payload = [{
        "announcement_id": announcement_id,
        "chunk_index": c["chunk_index"],
        "content": c["content"],
        "embedding": c["embedding"],
        "metadata": c.get("metadata", {})
    } for c in chunks]
    
    sb.table("announcement_chunks").insert(payload).execute()  # ì‚¬ìš© ì•ˆ í•¨
```

## ğŸ” 3. ë²¡í„° ê²€ìƒ‰ (Vector Search)

### 3.1 ê²€ìƒ‰ ë°©ì‹

**ê²€ìƒ‰ì€ ì¿¼ë¦¬ ì¤‘ì‹¬ (Query-based)ì…ë‹ˆë‹¤.**

1. **ì‚¬ìš©ì ì¿¼ë¦¬** â†’ **ì„ë² ë”© ë²¡í„° ë³€í™˜**
2. **ì„ë² ë”© ë²¡í„°** â†’ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°**
3. **ìœ ì‚¬ë„ ìˆœ ì •ë ¬** â†’ **Top-K ê²°ê³¼ ë°˜í™˜**

### 3.2 ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py`

#### âœ… í˜„ì¬ ì‚¬ìš© ì¤‘: ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ (`legal_chunks`)

```python
def search_similar_legal_chunks(query_embedding, top_k=5, filters=None):
    # legal_chunks í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰
    query = sb.table("legal_chunks").select("*")
    
    # source_type í•„í„°ë§ (law, manual, case ë“±)
    if filters and "source_type" in filters:
        query = query.eq("source_type", filters["source_type"])
    
    chunks = query.execute().data
    
    # í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    import numpy as np
    query_vec = np.array(query_embedding, dtype=np.float32)
    
    results = []
    for chunk in chunks:
        if chunk.get("embedding"):
            chunk_vec = np.array(chunk["embedding"], dtype=np.float32)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = dot product / (norm1 * norm2)
            similarity = np.dot(query_vec, chunk_vec) / (
                np.linalg.norm(query_vec) * np.linalg.norm(chunk_vec)
            )
            
            if similarity > 0.7:  # ì„ê³„ê°’
                results.append({
                    "id": chunk["id"],
                    "external_id": chunk.get("external_id", ""),
                    "source_type": chunk.get("source_type", "law"),
                    "title": chunk.get("title", ""),
                    "content": chunk.get("content", ""),
                    "score": float(similarity),
                    "metadata": chunk.get("metadata", {})
                })
    
    # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
    results.sort(key=lambda x: x["score"], reverse=True)
    return results[:top_k]
```

**Supabase RPC í•¨ìˆ˜ ì˜ˆì‹œ (SQL) - legal_chunksìš©:**
```sql
CREATE OR REPLACE FUNCTION match_legal_chunks(
    query_embedding vector(384),
    match_threshold float,
    match_count int,
    source_type_filter text DEFAULT NULL
)
RETURNS TABLE (
    id uuid,
    external_id text,
    source_type text,
    title text,
    content text,
    similarity float,
    metadata jsonb
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    SELECT
        lc.id,
        lc.external_id,
        lc.source_type,
        lc.title,
        lc.content,
        1 - (lc.embedding <=> query_embedding) as similarity,
        lc.metadata
    FROM legal_chunks lc
    WHERE 1 - (lc.embedding <=> query_embedding) > match_threshold
        AND (source_type_filter IS NULL OR lc.source_type = source_type_filter)
    ORDER BY lc.embedding <=> query_embedding
    LIMIT match_count;
END;
$$;
```

#### âš ï¸ ë ˆê±°ì‹œ: ê³µê³  ê²€ìƒ‰ (`announcement_chunks` - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

```python
# ë ˆê±°ì‹œ ì½”ë“œ (ì°¸ê³ ìš©, ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
def search_similar_chunks(query_embedding, top_k=5, filters=None):  # ë ˆê±°ì‹œ
    rpc_params = {
        "query_embedding": query_embedding,
        "match_threshold": 0.7,
        "match_count": top_k,
        "filters": filters or {}
    }
    
    result = sb.rpc("match_announcement_chunks", rpc_params).execute()  # ì‚¬ìš© ì•ˆ í•¨
    return result.data
```

### 3.3 ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Cosine Similarity)

**ê³µì‹:**
```
similarity = (A Â· B) / (||A|| Ã— ||B||)
```

- `A Â· B`: ë‘ ë²¡í„°ì˜ ë‚´ì  (dot product)
- `||A||`: ë²¡í„° Aì˜ í¬ê¸° (norm)
- `||B||`: ë²¡í„° Bì˜ í¬ê¸° (norm)
- ê²°ê³¼ê°’: -1 ~ 1 (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)

**pgvector ì—°ì‚°ì:**
- `<=>`: ì½”ì‚¬ì¸ ê±°ë¦¬ (1 - similarity)
- `<=>` ê°’ì´ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨

### 3.4 ê²€ìƒ‰ ìµœì í™”

#### ì¸ë±ì‹± (í˜„ì¬ ì‚¬ìš© ì¤‘)

```sql
-- legal_chunks ë²¡í„° ì¸ë±ìŠ¤ (IVFFlat)
CREATE INDEX IF NOT EXISTS legal_chunks_embedding_idx 
ON legal_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- source_type ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS legal_chunks_source_type_idx 
ON legal_chunks (source_type);
```

#### í•„í„°ë§ (í˜„ì¬ ì‚¬ìš© ì¤‘)

```python
# ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ í•„í„°
filters = {
    "source_type": "law"  # "law", "manual", "case"
}

# Supabase ì¿¼ë¦¬
result = sb.table("legal_chunks")\
    .select("*")\
    .eq("source_type", filters["source_type"])\
    .execute()
```

### 3.5 ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ (í˜„ì¬ ì‚¬ìš© ì¤‘)

**ì½”ë“œ ìœ„ì¹˜:** `core/supabase_vector_store.py::search_similar_legal_chunks`

ë²•ë¥  ë¬¸ì„œ ê²€ìƒ‰ì€ `legal_chunks` í…Œì´ë¸”ì„ ì‚¬ìš©í•˜ë©°, ê³„ì•½ì„œ ë¶„ì„ê³¼ ë²•ë¥  ìƒë‹´ì— í™œìš©ë©ë‹ˆë‹¤:

```python
def search_similar_legal_chunks(
    query_embedding: List[float],
    top_k: int = 5,
    filters: Optional[Dict] = None
):
    # source_type í•„í„°ë§ (law, manual, case ë“±)
    query = sb.table("legal_chunks").select("*")
    
    if filters and "source_type" in filters:
        query = query.eq("source_type", filters["source_type"])
    
    chunks = query.execute().data
    
    # í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    # (RPC í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    ...
```

**ì‚¬ìš© ì˜ˆì‹œ:**
- ê³„ì•½ì„œ ë¶„ì„ ì‹œ ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰
- ë²•ë¥  ìƒë‹´ ì±—ì—ì„œ ê´€ë ¨ ì¡°ë¬¸ ê²€ìƒ‰
- ìƒí™© ë¶„ì„ ì‹œ ìœ ì‚¬ ì¼€ì´ìŠ¤ ê²€ìƒ‰

## ğŸ”„ 4. ì „ì²´ í”Œë¡œìš° ì˜ˆì‹œ

### 4.1 âœ… í˜„ì¬ ì‚¬ìš© ì¤‘: ê³„ì•½ì„œ ë¶„ì„ ë° ë²•ë¥  ê²€ìƒ‰

#### ê³„ì•½ì„œ ë¶„ì„ í”Œë¡œìš°

```
1. ê³„ì•½ì„œ íŒŒì¼ ì—…ë¡œë“œ (PDF/HWPX)
   â†“
2. í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF/HWPX íŒŒì„œ)
   "ì œ1ì¡° (ê·¼ë¡œê¸°ê°„)... ì œ2ì¡° (ê·¼ë¡œì‹œê°„)..."
   â†“
3. RAG ê²€ìƒ‰ (legal_chunksì—ì„œ ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰)
   - ì¿¼ë¦¬: ê³„ì•½ì„œ ë³¸ë¬¸ ì¼ë¶€
   - ê²€ìƒ‰: legal_chunks í…Œì´ë¸”ì—ì„œ ìœ ì‚¬ ì¡°ë¬¸ ê²€ìƒ‰
   â†“
4. LLM ìœ„í—˜ ë¶„ì„ (Ollama)
   - ê²€ìƒ‰ëœ ë²•ë ¹ ì¡°ë¬¸ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
   - ìœ„í—˜ ì¡°í•­ ì‹ë³„ ë° ë¶„ì„
   â†“
5. ë¶„ì„ ê²°ê³¼ ì €ì¥
   - contract_analyses í…Œì´ë¸”ì— ì €ì¥
   - contract_issues í…Œì´ë¸”ì— ì´ìŠˆë³„ ìƒì„¸ ì €ì¥
```

#### ë²•ë¥  ê²€ìƒ‰ í”Œë¡œìš°

```
1. ì‚¬ìš©ì ì¿¼ë¦¬
   "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
   â†“
2. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
   "ìˆ˜ìŠµ ê¸°ê°„ í•´ê³  ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
   â†’ [0.15, 0.25, ..., 0.85] (384ì°¨ì›)
   â†“
3. ë²¡í„° ê²€ìƒ‰ (legal_chunks í…Œì´ë¸”)
   - source_type="law" í•„í„°ë§
   - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
   - ì²­í¬ A: similarity = 0.92 (ê·¼ë¡œê¸°ì¤€ë²• ì œ27ì¡°)
   - ì²­í¬ B: similarity = 0.88 (ê·¼ë¡œê¸°ì¤€ë²• ì‹œí–‰ë ¹)
   â†“
4. Top-K ê²°ê³¼ ì„ íƒ (top_k=5)
   [ì²­í¬ A, ì²­í¬ B, ...]
   â†“
5. LLM ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
   "ê´€ë ¨ ë²•ë ¹:
   - ê·¼ë¡œê¸°ì¤€ë²• ì œ27ì¡°: ìˆ˜ìŠµê¸°ê°„ ì¤‘ í•´ê³ ...
   - ê·¼ë¡œê¸°ì¤€ë²• ì‹œí–‰ë ¹: ìˆ˜ìŠµê¸°ê°„ì€...
   ..."
   â†“
6. LLM ë‹µë³€ ìƒì„± (Ollama)
   "ìˆ˜ìŠµ ê¸°ê°„ ì¤‘ í•´ê³ ì— ëŒ€í•œ ë²•ì  ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
   1. ê·¼ë¡œê¸°ì¤€ë²• ì œ27ì¡°ì— ë”°ë¥´ë©´...
   ..."
```

### 4.2 âš ï¸ ë ˆê±°ì‹œ: ê³µê³  ì—…ë¡œë“œ ë° ì¸ë±ì‹± (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

```
âš ï¸ ì´ í”Œë¡œìš°ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

1. íŒŒì¼ ì—…ë¡œë“œ (PDF)
   â†“
2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
   â†“
3. ì²­í¬ ë¶„í• 
   â†“
4. ì„ë² ë”© ìƒì„±
   â†“
5. ë²¡í„° ì €ì¥ (announcement_chunks)  â† ë ˆê±°ì‹œ
   â†“
6. LLM ë¶„ì„
   â†“
7. ë¶„ì„ ê²°ê³¼ ì €ì¥ (announcement_analysis)  â† ë ˆê±°ì‹œ
```

## ğŸ“Š 5. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### 5.1 ì£¼ìš” í…Œì´ë¸”

#### âš ï¸ ë ˆê±°ì‹œ í…Œì´ë¸” (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

**`announcements`** (ë ˆê±°ì‹œ)
- ê³µê³  ê´€ë ¨ ê¸°ëŠ¥ì€ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- `id`: UUID (PK)
- `source`: ì¶œì²˜
- `external_id`: ì™¸ë¶€ ì‹œìŠ¤í…œ ID
- `title`: ì œëª©
- `version`: ë²„ì „ ë²ˆí˜¸
- `content_hash`: ë‚´ìš© í•´ì‹œ (ì¤‘ë³µ ê°ì§€)

**`announcement_chunks`** (ë ˆê±°ì‹œ)
- ê³µê³  ì²­í¬ ë° ì„ë² ë”© ì €ì¥ í…Œì´ë¸” (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
- `id`: UUID (PK)
- `announcement_id`: ê³µê³  ID (FK)
- `chunk_index`: ì²­í¬ ìˆœì„œ
- `content`: ì²­í¬ í…ìŠ¤íŠ¸
- `embedding`: vector(384) - ì„ë² ë”© ë²¡í„°
- `metadata`: JSONB - ë©”íƒ€ë°ì´í„°

#### âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í…Œì´ë¸”

**`legal_chunks`** (í˜„ì¬ ì‚¬ìš© ì¤‘)
- ë²•ë¥  ë¬¸ì„œ ì²­í¬ ë° ì„ë² ë”© ì €ì¥ í…Œì´ë¸”
- ê³„ì•½ì„œ ë¶„ì„, ë²•ë¥  ê²€ìƒ‰ì— ì‚¬ìš©
- `id`: UUID (PK)
- `external_id`: ì™¸ë¶€ ë¬¸ì„œ ID
- `source_type`: ë¬¸ì„œ íƒ€ì… (law, manual, case)
- `title`: ë¬¸ì„œ ì œëª©
- `content`: ì²­í¬ í…ìŠ¤íŠ¸
- `embedding`: vector(384) - ì„ë² ë”© ë²¡í„°
- `metadata`: JSONB - ë©”íƒ€ë°ì´í„°
- `chunk_index`: ì²­í¬ ìˆœì„œ
- `file_path`: ì›ë³¸ íŒŒì¼ ê²½ë¡œ

**`contract_analyses`** (í˜„ì¬ ì‚¬ìš© ì¤‘)
- ê³„ì•½ì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥
- `id`: UUID (PK)
- `doc_id`: ë¬¸ì„œ ID
- `title`: ê³„ì•½ì„œ ì œëª©
- `risk_score`: ìœ„í—˜ë„ ì ìˆ˜
- `risk_level`: ìœ„í—˜ë„ ë ˆë²¨
- `contract_text`: ê³„ì•½ì„œ ì›ë¬¸ í…ìŠ¤íŠ¸
- `summary`: ë¶„ì„ ìš”ì•½
- `user_id`: ì‚¬ìš©ì ID (ì„ íƒ)

**`contract_issues`** (í˜„ì¬ ì‚¬ìš© ì¤‘)
- ê³„ì•½ì„œ ì´ìŠˆ ìƒì„¸ ì •ë³´
- `id`: UUID (PK)
- `contract_analysis_id`: ê³„ì•½ì„œ ë¶„ì„ ID (FK)
- `issue_id`: ì´ìŠˆ ID
- `category`: ì´ìŠˆ ì¹´í…Œê³ ë¦¬
- `severity`: ìœ„í—˜ë„
- `summary`: ì´ìŠˆ ìš”ì•½
- `legal_basis`: ë²•ì  ê·¼ê±°

### 5.2 ì¸ë±ìŠ¤

#### âœ… í˜„ì¬ ì‚¬ìš© ì¤‘: legal_chunks ì¸ë±ìŠ¤

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ (IVFFlat) - legal_chunks
CREATE INDEX IF NOT EXISTS legal_chunks_embedding_idx 
ON legal_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- source_type ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS legal_chunks_source_type_idx 
ON legal_chunks (source_type);

-- external_id ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS legal_chunks_external_id_idx 
ON legal_chunks (external_id);
```

#### âš ï¸ ë ˆê±°ì‹œ: announcement_chunks ì¸ë±ìŠ¤ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ (IVFFlat) - ë ˆê±°ì‹œ
-- CREATE INDEX announcement_chunks_embedding_idx 
-- ON announcement_chunks 
-- USING ivfflat (embedding vector_cosine_ops)
-- WITH (lists = 100);
```

## ğŸ¯ 6. ê²€ìƒ‰ ì „ëµ ë¹„êµ

### 6.1 ë²¡í„° ê²€ìƒ‰ (Vector Search)
- **ë°©ì‹**: ì„ë² ë”© ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
- **ì¥ì **: ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰, ë™ì˜ì–´ ì²˜ë¦¬ ê°€ëŠ¥
- **ë‹¨ì **: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì€ ì•½í•¨

### 6.2 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Hybrid Search)
- **ë°©ì‹**: ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)
- **ì¥ì **: ì˜ë¯¸ ê²€ìƒ‰ + ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
- **êµ¬í˜„**: `core/tools/vector_search_tool.py`

### 6.3 MMR ì¬ë­í‚¹ (Maximal Marginal Relevance)
- **ë°©ì‹**: ìœ ì‚¬ë„ + ë‹¤ì–‘ì„± ê³ ë ¤
- **ì¥ì **: ì¤‘ë³µ ê²°ê³¼ ì œê±°, ë‹¤ì–‘í•œ ê²°ê³¼ ì œê³µ
- **êµ¬í˜„**: `core/tools/vector_search_tool.py`

## ğŸ”§ 7. ì„¤ì • ë° íŠœë‹

### 7.1 ì²­í‚¹ íŒŒë¼ë¯¸í„°

```env
# .env íŒŒì¼
CHUNK_SIZE=1000      # ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)
CHUNK_OVERLAP=200    # ì˜¤ë²„ë© í¬ê¸° (ë¬¸ì ìˆ˜)
```

**ê¶Œì¥ê°’:**
- **ì§§ì€ ë¬¸ì„œ**: `CHUNK_SIZE=500, CHUNK_OVERLAP=100`
- **ê¸´ ë¬¸ì„œ**: `CHUNK_SIZE=2000, CHUNK_OVERLAP=400`
- **ë²•ë¥  ë¬¸ì„œ**: `CHUNK_SIZE=1500, CHUNK_OVERLAP=300`

### 7.2 ê²€ìƒ‰ íŒŒë¼ë¯¸í„°

```python
# ê²€ìƒ‰ ì‹œ
top_k = 5              # ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
match_threshold = 0.7  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
```

**ê¶Œì¥ê°’:**
- **ì¼ë°˜ ê²€ìƒ‰**: `top_k=5, match_threshold=0.7`
- **ì •ë°€ ê²€ìƒ‰**: `top_k=3, match_threshold=0.85`
- **ê´‘ë²”ìœ„ ê²€ìƒ‰**: `top_k=10, match_threshold=0.6`

### 7.3 ì„ë² ë”© ëª¨ë¸ ì„ íƒ

```env
# ë¬¸ì„œ ì„ë² ë”© (ê³µê³ ë¬¸, ê³„ì•½ì„œ)
LOCAL_EMBEDDING_MODEL=BAAI/bge-m3          # 1024ì°¨ì›, ë‹¤êµ­ì–´

# ê¸°ì—… ì„ë² ë”© (íŒ€, ê¸°ì—…)
COMPANY_EMBED_MODEL=BAAI/bge-small-en-v1.5  # 384ì°¨ì›, ë¹ ë¦„
```

## ğŸ“ 8. ì£¼ìš” ì½”ë“œ ì°¸ì¡°

### 8.1 ì²­í‚¹
- `core/document_processor_v2.py::to_chunks()` - ì²­í¬ ë¶„í• 
- `core/document_processor_v2.py::SimpleTextSplitter` - ë¶„í•  ì•Œê³ ë¦¬ì¦˜
- `core/legal_chunker.py` - ë²•ë¥  ë¬¸ì„œ ì „ìš© ì²­í‚¹ (ì„ íƒì‚¬í•­)

### 8.2 ì„ë² ë”©
- `core/generator_v2.py::embed()` - ë°°ì¹˜ ì„ë² ë”©
- `core/generator_v2.py::embed_one()` - ë‹¨ì¼ ì„ë² ë”©

### 8.3 ë²¡í„° ê²€ìƒ‰ (í˜„ì¬ ì‚¬ìš© ì¤‘)
- âœ… `core/supabase_vector_store.py::search_similar_legal_chunks()` - ë²•ë¥  ê²€ìƒ‰ (í˜„ì¬ ì‚¬ìš©)
- âœ… `core/legal_rag_service.py::_search_legal_chunks()` - ë²•ë¥  RAG ê²€ìƒ‰ (í˜„ì¬ ì‚¬ìš©)
- âš ï¸ `core/supabase_vector_store.py::search_similar_chunks()` - ê³µê³  ê²€ìƒ‰ (ë ˆê±°ì‹œ, ì‚¬ìš© ì•ˆ í•¨)
- âš ï¸ `core/orchestrator_v2.py::search_similar_announcements()` - ê³µê³  ê²€ìƒ‰ (ë ˆê±°ì‹œ, ì‚¬ìš© ì•ˆ í•¨)

### 8.4 RAG íŒŒì´í”„ë¼ì¸ (í˜„ì¬ ì‚¬ìš© ì¤‘)
- âœ… `core/legal_rag_service.py::analyze_contract()` - ê³„ì•½ì„œ ë¶„ì„ RAG (í˜„ì¬ ì‚¬ìš©)
- âœ… `core/legal_rag_service.py::chat_with_context()` - ë²•ë¥  ìƒë‹´ ì±— (í˜„ì¬ ì‚¬ìš©)
- âœ… `core/legal_rag_service.py::analyze_situation_detailed()` - ìƒí™© ë¶„ì„ (í˜„ì¬ ì‚¬ìš©)
- âš ï¸ `core/orchestrator_v2.py::process_announcement()` - ê³µê³  ì²˜ë¦¬ (ë ˆê±°ì‹œ, ì‚¬ìš© ì•ˆ í•¨)

## ğŸš€ 9. ì„±ëŠ¥ ìµœì í™”

### 9.1 ë²¡í„° ì¸ë±ìŠ¤
- IVFFlat ì¸ë±ìŠ¤ ì‚¬ìš© (ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰)
- `lists` íŒŒë¼ë¯¸í„° ì¡°ì • (100-1000 ê¶Œì¥)

### 9.2 ë°°ì¹˜ ì²˜ë¦¬
- ì„ë² ë”© ìƒì„± ì‹œ ë°°ì¹˜ ì²˜ë¦¬ (`embed()` ë©”ì„œë“œ)
- ë²¡í„° ì €ì¥ ì‹œ ì¼ê´„ ì‚½ì… (`bulk_upsert_chunks()`)

### 9.3 ìºì‹±
- ì„ë² ë”© ëª¨ë¸ ì§€ì—° ë¡œë“œ (ì‹±ê¸€í†¤ íŒ¨í„´)
- Supabase í´ë¼ì´ì–¸íŠ¸ ì§€ì—° ì´ˆê¸°í™”

## ğŸ“š ì°¸ê³  ìë£Œ

- [Supabase pgvector ë¬¸ì„œ](https://supabase.com/docs/guides/ai/vector-columns)
- [sentence-transformers ë¬¸ì„œ](https://www.sbert.net/)
- [LangChain RAG ê°€ì´ë“œ](https://python.langchain.com/docs/use_cases/question_answering/)

